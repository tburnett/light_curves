{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bayesian\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import *\n",
    "from utilities.ipynb_docgen import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Blocks\n",
    "\n",
    "> Partition a light curve with the Bayesian Block algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm depends on a 'fitness' function of the light curve, an evaluation of the \n",
    "likelihoods for a set of sequential cells. There are two such, using the number of counts, and the Kerr likelihood.\n",
    "\n",
    "- `CountFitness`\n",
    "- `LikelihoodFitness`\n",
    "\n",
    "See the [Bayesian Block reference](https://arxiv.org/pdf/1207.5578.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats.bayesian_blocks import FitnessFunc\n",
    "from light_curves.lightcurve import get_lightcurve, flux_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function data_setup failed: expr must be a string to be evaluated, <class 'NoneType'> given\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expr must be a string to be evaluated, <class 'NoneType'> given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0de8d408e733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mnbdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_setup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmjd_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/d/OneDrive/work/light_curves/utilities/ipynb_docgen.py\u001b[0m in \u001b[0;36mnbdoc\u001b[0;34m(fun, name, *pars, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;31m# run it and collect its local symbol table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Function {fun.__name__} failed: {e}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0de8d408e733>\u001b[0m in \u001b[0;36mdata_setup\u001b[0;34m(lcs, mjd_query, names)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcapture_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'printout'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprintout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lightcurve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPointSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmjd_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mflux_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfignum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"expr must be a string to be evaluated, {type(expr)} given\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expr must be a string to be evaluated, <class 'NoneType'> given"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "from light_curves.config import Config, Files, PointSource\n",
    "\n",
    "lcs ={}\n",
    "def data_setup(lcs = lcs, mjd_query='54750<t<54855', names=['Geminga','3C 279']):\n",
    "    \"\"\"\n",
    "    ## Generate data sets for an AGN and a pulsar\n",
    "    {printout}\n",
    "    \n",
    "    Choose the time interval, {mjd_query} to bracket a modest flare of the AGN.\n",
    "     \n",
    "    <table>\n",
    "    <tr> <td>Pulsar</td><td>AGN</td></tr>\n",
    "    <tr>\n",
    "    <td>{fig1}</td> <td>{fig2}</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "    \"\"\"\n",
    "    \n",
    "    from light_curves.config import Config, Files, PointSource\n",
    "    from light_curves.lightcurve import get_lightcurve, flux_plot\n",
    "    config = Config(use_cache=True)\n",
    "    files = Files()\n",
    "    figs=[]\n",
    "    plt.rc('font', size=20)\n",
    "    with capture_print('printout') as printout:\n",
    "        for i,name in enumerate(names):\n",
    "            lc = lcs[name] = get_lightcurve(config, files, PointSource(name)).query(mjd_query)\n",
    "            fig= flux_plot(config,lc, fignum=i, title=name)\n",
    "            figs.append(figure(fig, width=500))\n",
    "    fig1, fig2 = figs\n",
    "    mjd_query = mjd_query.replace('<', '&lt;')\n",
    "    return locals()\n",
    "\n",
    "if Files().valid:\n",
    "    nbdoc(data_setup, lcs, mjd_query=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CountFitness(FitnessFunc):\n",
    "    \"\"\"\n",
    "    Adapted version of a astropy.stats.bayesian_blocks.FitnessFunc\n",
    "    Considerably modified to give the `fitness function` access to the cell data.\n",
    "    Implements the Event model using exposure instead of time.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lc, p0=0.05,):\n",
    "        \"\"\"lc  : a LightCurve data table, with  exposure (fexp) and counts (n),\n",
    "            as well as a representation of the likelihood for each cell\n",
    "        \"\"\"\n",
    "        self.p0=p0\n",
    "        self.df= df= lc\n",
    "        N = self.N = len(df)\n",
    "        # Invoke empirical function from Scargle 2012\n",
    "        self.ncp_prior = self.p0_prior(N)\n",
    "\n",
    "        #actual times for bin edges\n",
    "        t = df.t.values\n",
    "        dt = df.tw.values/2\n",
    "        self.mjd = np.concatenate([t-dt, [t[-1]+dt[-1]] ] ) # put one at the end\n",
    "        self.name = self.__class__.__name__\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "\n",
    "        # counts per cell\n",
    "        self.nn = df.n.values\n",
    "        assert min(self.nn)>0, 'Attempt to Include a cell with no contents'\n",
    "\n",
    "        # edges and block_length use exposure as \"time\"\n",
    "        fexp = df.fexp.values\n",
    "        self.edges = np.concatenate([[0], np.cumsum(fexp)])\n",
    "        self.block_length = self.edges[-1] - self.edges\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return f'{self.name}: {self.N} cells, spanning {self.block_length[0]:.1f} days, prior={self.ncp_prior:.1f}'\n",
    "        \n",
    "    def __call__(self, R):\n",
    "        \"\"\" The fitness function needed for BB algorithm\n",
    "        For cells 0..R return array of length R+1 of the maximum log likelihoods for combined cells\n",
    "        0..R, 1..R, ... R\n",
    "        \"\"\"\n",
    "        # exposures and corresponding counts\n",
    "        w_k = self.block_length[:R + 1] - self.block_length[R + 1]\n",
    "        N_k = np.cumsum(self.nn[:R + 1][::-1])[::-1]\n",
    "\n",
    "        # Solving eq. 26 from Scargle 2012 for maximum $\\lambda$ gives\n",
    "        return N_k * (np.log(N_k) - np.log(w_k))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the Bayesian Blocks model given the specified fitness function.\n",
    "        Refactored version using code from bayesian_blocks.FitnesFunc.fit\n",
    "        Returns\n",
    "        -------\n",
    "        edges : ndarray\n",
    "            array containing the (M+1) edges, in MJD units, defining the M optimal bins\n",
    "        \"\"\"\n",
    "        # This is the basic Scargle algoritm, copied almost verbatum\n",
    "        # ---------------------------------------------------------------\n",
    "\n",
    "        # arrays to store the best configuration\n",
    "        N = self.N\n",
    "        best = np.zeros(N, dtype=float)\n",
    "        last = np.zeros(N, dtype=int)\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Start with first data cell; add one cell at each iteration\n",
    "        # ----------------------------------------------------------------\n",
    "        for R in range(N):\n",
    "\n",
    "            # evaluate fitness function\n",
    "            fit_vec = self(R)\n",
    "\n",
    "            A_R = fit_vec - self.ncp_prior\n",
    "            A_R[1:] += best[:R]\n",
    "\n",
    "            i_max = np.argmax(A_R)\n",
    "            last[R] = i_max\n",
    "            best[R] = A_R[i_max]\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "        # Now find changepoints by iteratively peeling off the last block\n",
    "        # ----------------------------------------------------------------\n",
    "        change_points = np.zeros(N, dtype=int)\n",
    "        i_cp = N\n",
    "        ind = N\n",
    "        while True:\n",
    "            i_cp -= 1\n",
    "            change_points[i_cp] = ind\n",
    "            if ind == 0:\n",
    "                break\n",
    "            ind = last[ind - 1]\n",
    "        change_points = change_points[i_cp:]\n",
    "\n",
    "        return self.mjd[change_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_hide\n",
    "\n",
    "def doc_countfitness( fitness, light_curve_dict, source_name):\n",
    "    \"\"\"\n",
    "    ### {class_name} test with source {source_name}\n",
    "         \n",
    "    Create object: `bbfitter = {class_name}(lc)`\n",
    "    \n",
    "    Object description:   {bbfitter}\n",
    "    \n",
    "    Then `bbfitter({n})` returns the values\n",
    "        {values}\n",
    "   \n",
    "    Finally, the partition algorithm, 'bbfitter.fit()' returns {cffit}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lc = light_curve_dict[source_name]\n",
    "    bbfitter = fitness(lc)\n",
    "    class_name = bbfitter.name\n",
    "    n = 10\n",
    "    values  = np.array(bbfitter(n)).round()    \n",
    "    cffit = bbfitter.fit()\n",
    "    \n",
    "    return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from light_curves.config import Config, Files, PointSource\n",
    "from light_curves.lightcurve import get_lightcurve, flux_plot\n",
    "if Files().valid:\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='Geminga')\n",
    "    nbdoc(doc_countfitness, CountFitness, light_curve_dict = lcs, source_name='3C 279')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LikelihoodFitness(CountFitness):\n",
    "    \"\"\" Fitness function that uses the full likelihood\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lc,  p0=0.05, npt=25):\n",
    "        self.npt = npt\n",
    "        super().__init__(lc, p0)\n",
    "        \n",
    "    def setup(self):\n",
    "        df = self.df\n",
    "        N = self.N\n",
    "        \n",
    "        def liketable(prep):\n",
    "            return prep.create_table(self.npt)\n",
    "        \n",
    "        self.tables = df.fit.apply(liketable).values\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}: {self.N} cells,  prior={self.ncp_prior:.1f}'\n",
    "\n",
    "    def __call__(self, R):\n",
    "        \n",
    "        a, y  = self.tables[R]\n",
    "        x = np.linspace(*a)\n",
    "        y = np.zeros(self.npt)\n",
    "        rv = np.empty(R+1)\n",
    "        for i in range(R, -1, -1): \n",
    "            a, yi = self.tables[i]\n",
    "            xi = np.linspace(*a)\n",
    "            y += np.interp(x, xi, yi, left=-np.inf, right=-np.inf)\n",
    "            amax = np.argmax(y)\n",
    "            rv[i] =y[amax]\n",
    "        return rv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Files().valid:\n",
    "    nbdoc(doc_countfitness, LikelihoodFitness, light_curve_dict = lcs, source_name='Geminga')\n",
    "    nbdoc(doc_countfitness, LikelihoodFitness, light_curve_dict = lcs, source_name='3C 279')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_weights(self, bins=None, contiguous=False):\n",
    "    \"\"\" \n",
    "    Parameter:\n",
    "        bins : None | float | array\n",
    "            if None, use defaults\n",
    "            Otherwise an array of MJD bin edges\n",
    "        contiguous : bool\n",
    "            if True ignore bins arg and use a list of contiguous exposure intervals\n",
    "\n",
    "    Returns: a BinnedWeight object for access to each set of binned weights\n",
    "        The object can be indexed, or used in a for loop\n",
    "        bw[i] returns a  dict (t, tw, fexp, w, S, B)\n",
    "        where t   : bin center time (MJD)\n",
    "              tw  : bin width in days (assume 1 if not preseent)\n",
    "              fexp: associated fractional exposure\n",
    "              w   : array of weights for the time range\n",
    "              S,B : predicted source, background counts for this bin\n",
    "        \"\"\"\n",
    "    if contiguous:\n",
    "        assert bins is None, 'contiguous selected'\n",
    "        a, b = self.get_contiguous_exposures()\n",
    "        edges = np.empty(len(a)+1)\n",
    "        edges[0] = a[0]\n",
    "        edges[1:-1] = 0.5*(a[1:]+b[:-1])\n",
    "        edges[-1]= b[-1]\n",
    "        bins = edges\n",
    "    return BinnedWeights(self, bins)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_bb_partition(config, lc, fitness_class=CountFitness, p0=0.05):    \n",
    "\n",
    "    \"\"\"Perform Bayesian Block partition of the cells found in a light curve\n",
    "    \n",
    "    - lc : input light curve\n",
    "    - fitness_func : \n",
    "    \n",
    "    return edges for partition\n",
    "    \"\"\"\n",
    "    cells = lc\n",
    "    assert 'fit' in cells.columns, 'Expect the dataframe ho have the Poisson representation'\n",
    "    assert issubclass(fitness_class,CountFitness), 'fitness_class wrong'\n",
    "    # Now run the astropy Bayesian Blocks code using my version of the 'event' model\n",
    "    fitness = fitness_class(lc, p0=p0)\n",
    "    edges = fitness.fit() \n",
    "\n",
    "    if config.verbose>0:\n",
    "        print(f'Partitioned {fitness.N} cells into {len(edges)-1} blocks, with prior {fitness.ncp_prior:.1f}'\\\n",
    "              f' using {fitness.__class__.__name__} ' )\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse_hide\n",
    "\n",
    "def test_bb(lcs, name, fitness):\n",
    "    \"\"\"\n",
    "    #&# Display results of the BB partition for {name}\n",
    "    \n",
    "    {lc_fig}\n",
    "    \"\"\"\n",
    "    files = Files()\n",
    "    config = Config(use_cache=True)\n",
    "    \n",
    "    lc = lcs[name]\n",
    "    edges = get_bb_partition(config, lc, fitness) \n",
    "    lc_fig = flux_plot(config, lc, title=f'{name} partition with {fitness.__name__}')\n",
    "    lc_fig.width=400\n",
    "    ax = lc_fig.axes[0]\n",
    "    edges = np.concatenate([edges, [edges[-1]] ])\n",
    "    for  i,t in enumerate(edges[::2]):\n",
    "        if 2*i+1==len(edges): break\n",
    "        t2 = edges[2*i+1]\n",
    "        ax.axvspan(t, t2, color='lightcyan')\n",
    "    for t in edges:\n",
    "        ax.axvline(t, ls=':', color='cyan')\n",
    "    return locals()\n",
    "\n",
    "if Files().valid:\n",
    "    nbdoc(test_bb, lcs, '3C 279', CountFitness)\n",
    "    nbdoc(test_bb, lcs, '3C 279', LikelihoodFitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(use_cache=False)\n",
    "files = Files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = PointSource('Geminga')\n",
    "edges = get_bb_partition(config, lcs['Geminga'], LikelihoodFitness) \n",
    "lcx = get_lightcurve(config, files, source, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_plot(config, lcx);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
