{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp simulation\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "> Generate simulated cells using the weighted likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import poisson\n",
    "from light_curves.loglike import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Sampler():\n",
    "    \"\"\" Sample an arbitrary function or histogram\n",
    "    \n",
    "    - func -- the function, or a histogram\n",
    "    - a,b  -- limits (default 0,1)\n",
    "    - n    -- table size (ignored if a histogram)\n",
    "    \n",
    "    Note the property `mean` is the expected mean.\n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self, func, limits=(0,1), n=100):\n",
    "\n",
    "        a,b = limits\n",
    "        self.x = np.linspace(a,b,n+1) # bin edges\n",
    "        dx = (b-a)/(n)/2\n",
    "\n",
    "        if not hasattr(func, '__len__'):\n",
    "            # evaluate at bin centers\n",
    "            y = [func(t-dx) for t in self.x]\n",
    "        else:\n",
    "            n = len(func) \n",
    "            self.x = np.linspace(a,b,n)\n",
    "            y = func\n",
    "        cy = np.cumsum(y)\n",
    "        d = cy[-1]-cy[0]\n",
    "        self.sy = (cy-cy[0])/d\n",
    "        \n",
    "        self.mean = np.sum( (self.x-dx) * y) / d\n",
    "\n",
    "    def _evaluate(self, r):\n",
    "        \"\"\"evaluate inverse integral. expect 0<r<1 \"\"\"\n",
    "        return np.interp(r, self.sy, self.x)\n",
    "    \n",
    "    def __call__(self, size):\n",
    "        \"\"\"Generate `size` values\n",
    "        \"\"\"\n",
    "        from scipy.stats import uniform\n",
    "        return self._evaluate(uniform.rvs(size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(lambda x: x, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Sampler\" class=\"doc_header\"><code>class</code> <code>Sampler</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Sampler</code>(**`func`**, **`limits`**=*`(0, 1)`*, **`n`**=*`100`*)\n",
       "\n",
       "Sample an arbitrary function or histogram\n",
       "\n",
       "- func -- the function, or a histogram\n",
       "- a,b  -- limits (default 0,1)\n",
       "- n    -- table size (ignored if a histogram)\n",
       "\n",
       "Note the property `mean` is the expected mean."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Sampler.__call__\" class=\"doc_header\"><code>Sampler.__call__</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sampler.__call__</code>(**`size`**)\n",
       "\n",
       "Generate `size` values\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "show_doc(Sampler)\n",
    "show_doc(Sampler.__call__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sampler tests:  Gaussian and quadratic functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "sf = Sampler(lambda x: np.exp(-(x**2)/2), limits=(-4, 4) )\n",
    "\n",
    "data = sf(10000)\n",
    "tests = np.array([np.abs(data.mean()), np.abs(data.std()-1) ])\n",
    "assert np.all(tests<5e-2 ), f'Failed Tests: mean {data.mean()}, std {data.std()}'\n",
    "\n",
    "func = lambda x: x**2\n",
    "wfun = Sampler(func)\n",
    "\n",
    "test2 = wfun.mean,  np.mean(wfun(1000))\n",
    "assert np.abs( test2[0]-test2[1] ) < 1e-1, f'Not almost equal: {test2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightGenerator(Sampler):\n",
    "    \"\"\"Generate a set of weights\n",
    "    \n",
    "    - `func` -- nominal weight distribution function, evaluated on (0,1)\n",
    "    - `alpha, beta` -- (default 0,0). Values for $\\\\alpha$, $\\\\beta$.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, func, alpha=0, beta=0, n=100):\n",
    "        if alpha==0 and beta==0:\n",
    "            fprime = func\n",
    "        else:\n",
    "            # weight the function\n",
    "            fprime = lambda w: func(w) * ( 1 + alpha*w + beta*(1-w) )\n",
    "        super().__init__( fprime, limits=(0,1),  n=n)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"WeightGenerator\" class=\"doc_header\"><code>class</code> <code>WeightGenerator</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>WeightGenerator</code>(**`func`**, **`alpha`**=*`0`*, **`beta`**=*`0`*, **`n`**=*`100`*) :: [`Sampler`](/light_curves/simulation.html#Sampler)\n",
       "\n",
       "Generate a set of weights\n",
       "\n",
       "- `func` -- nominal weight distribution function, evaluated on (0,1)\n",
       "- `alpha, beta` -- (default 0,0). Values for $\\alpha$, $\\beta$."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "show_doc(WeightGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "wg = WeightGenerator(func)\n",
    "test2 = wg.mean,  np.mean(wg(1000))\n",
    "assert np.abs( test2[0]-test2[1] ) < 1e-1, f'Not almost equal: {test2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_cell(wfun, mu, alpha=0, beta=0):\n",
    "    \"\"\" Generate a cell\n",
    "\n",
    "    - `wfun` -- weight function, or histogram. \n",
    "        Defined on (0,1)\n",
    "    - `mu` -- number of expected weights, on average\n",
    "    - `alpha`, `beta`  -- default 0,0; values for $\\\\alpha$ and  $\\\\beta$ for this cell \n",
    "    \n",
    "    Returns a dict with:\n",
    "    - `n` -- actual generated number of weights, from Poisson \n",
    "    - `w` -- array of weights \n",
    "    - `S, B` -- expected values for $\\sum w$ and $\\sum(1-w)$, calulated from wfun\n",
    "    \"\"\"\n",
    "\n",
    "    wgen_nominal = WeightGenerator(wfun)\n",
    "    wgen_cell =wgen_nominal if alpha==0 and beta==0 else WeightGenerator(wfun, alpha, beta)\n",
    "    \n",
    "    # adjust expected number of events:\n",
    "    wbar = wgen_nominal.mean\n",
    "    mu_cell = mu * (1+alpha*wbar+beta*(1-wbar))\n",
    "   \n",
    "    # the weight array\n",
    "    n = poisson.rvs(mu_cell )    \n",
    "    w = wgen_cell(n)\n",
    "    \n",
    "    S = wgen_nominal.mean * mu\n",
    "    B = mu-S\n",
    "    \n",
    "    return dict(\n",
    "        n=n,\n",
    "        w=np.array(w, np.float32), #np.uint8),\n",
    "        S=S,\n",
    "        B=B,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"generate_cell\" class=\"doc_header\"><code>generate_cell</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>generate_cell</code>(**`wfun`**, **`mu`**, **`alpha`**=*`0`*, **`beta`**=*`0`*)\n",
       "\n",
       "Generate a cell\n",
       "\n",
       "- `wfun` -- weight function, or histogram. \n",
       "    Defined on (0,1)\n",
       "- `mu` -- number of expected weights, on average\n",
       "- `alpha`, `beta`  -- default 0,0; values for $\\alpha$ and  $\\beta$ for this cell \n",
       "\n",
       "Returns a dict with:\n",
       "- `n` -- actual generated number of weights, from Poisson \n",
       "- `w` -- array of weights \n",
       "- `S, B` -- expected values for $\\sum w$ and $\\sum(1-w)$, calulated from wfun"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(generate_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a function peaked at both ends, generate equal signal and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with alpha=0.1, beta=None\n",
      "Generated cell info:\n",
      "light_curves.loglike.LogLike:  10435 weights, S 4998.5, B 5001.5\n",
      "1-D fit info:\n",
      "counts      10435.000\n",
      "flux            1.084\n",
      "sig_flux        0.016\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "def test_gen(alpha, beta, mu=10000, tol=3, quiet=True):\n",
    "    wfun = lambda x: (x-0.5)**2\n",
    "    pd.set_option('display.precision', 3)\n",
    "    if not quiet: print(f'Test with alpha={alpha}, beta={beta}')\n",
    "    cell = generate_cell( wfun, mu,  alpha, 0 if beta is None else beta)\n",
    "    #\n",
    "    ll = LogLike(cell); \n",
    "    if not quiet: print(f'Generated cell info:\\n{ ll}')\n",
    "\n",
    "    fit = ll.fit_info(beta is None )\n",
    "    if not quiet: print(f'{2 if beta is not None else 1}-D fit info:\\n{pd.Series(fit)}')\n",
    "    t, sigt = fit['flux']-(1+alpha),  fit['sig_flux']\n",
    "    check_alpha = '' if  np.abs(t)<tol*sigt else f'alpha: abs({t:.3f}) > {tol} * {sigt:.3f}'\n",
    "\n",
    "    if beta is None:\n",
    "        assert not bool(check_alpha), f'Failed: {check_alpha} '\n",
    "    else:\n",
    "        t, sigt = fit['beta']-beta, fit['sig_beta']\n",
    "        check_beta ='' if np.abs(t)<tol*sigt else f'beta: abs({t:.3f}) > {tol} * {sigt:.3f}'\n",
    "\n",
    "        assert not ( bool(check_alpha)  or bool(check_beta)), f'{check_alpha}  {check_beta}'\n",
    "test_gen(0,None)\n",
    "test_gen(10,None)\n",
    "#test_gen(10, 0, tol=5, quiet=False)\n",
    "test_gen(0,2)\n",
    "test_gen(0.1, None, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a set of poisson-like fits to the likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "wfun = lambda x: (x-0.5)**2\n",
    "mu = 100\n",
    "alpha = 0.1\n",
    "pfits  = [PoissonRep(LogLike(generate_cell( wfun, mu ,alpha))) for i in range(40000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.06278923607867916, 1.0239380269983502)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmean = 1+alpha\n",
    "def pull(p):\n",
    "    f, (l, h)  = p.flux, p.errors\n",
    "    s = (h-l)/2\n",
    "    return (f-fmean)/s\n",
    "pulls = np.array(list(map(pull, pfits)))\n",
    "pulls.mean(), pulls.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "flux = np.array([pfit.flux for pfit in pfits])\n",
    "ax.hist((flux-1-alpha)/flux.std() , np.linspace(-5, 5, 21), lw=2, histtype='step', log=True);\n",
    "ax.set(ylim=(0.8,None), xlabel='pull'); ax.grid(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare observed std with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppers = np.array([p.errors[1]-p.flux for p in pfits])\n",
    "lowers = np.array([p.flux - p.errors[0] for p in pfits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean errors: 0.165, STD: 0.166 \n"
     ]
    }
   ],
   "source": [
    "print(f'mean errors: {(np.mean(uppers)+ np.mean(lowers))/2:.3f}, STD: {flux.std():.3f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_load_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_poisson.ipynb.\n",
      "Converted 09_simulation.ipynb.\n",
      "Converted 10_loglike.ipynb.\n",
      "Converted 11_lightcurve.ipynb.\n",
      "Converted 12_roadmap.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sat Dec 19 04:47:45 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
