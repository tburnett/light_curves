{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from utilities.ipynb_docgen import *\n",
    "from nbdev import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B1259 Analysis\n",
    "> Create a B1259 light curve using Bayesean Blocks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "from wtlike.config import *\n",
    "from wtlike.bayesian import *\n",
    "from wtlike.simulation import *\n",
    "from wtlike.lightcurve import *\n",
    "from wtlike.loglike import *\n",
    "from wtlike.cells import *\n",
    "config = Config()\n",
    "\n",
    "def bb_overplot(config, lc, bb_fit, ax=None, colors=('black', 'papayawhip', 'blue'), **kwargs):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,4)) if not ax else (ax.figure, ax)\n",
    "    flux_plot(config, lc, ax=ax, colors=colors, **kwargs)\n",
    "    flux_plot(config, bb_fit, ax=ax, step=True, colors=colors, **kwargs)\n",
    "    \n",
    "def analyze_data(config, source):\n",
    "    \"\"\"\n",
    "    Analyze data from the source\n",
    "    \n",
    "    Returns, data a partitioned light curves\n",
    "    \"\"\"\n",
    "    lc = get_lightcurve(config, source)\n",
    "    cells = get_cells(config, source)\n",
    "    edges = get_bb_partition(config, lc, LikelihoodFitness, key='bb-Geminga-test') \n",
    "    bb_cells = partition_cells(config, cells, edges);\n",
    "    bb_lc  = fit_cells(config, bb_cells, )\n",
    "    return lc, bb_lc\n",
    "\n",
    "def fit_table(lc, expect=1.0):\n",
    "    \"\"\"Generate a summary table from a light curve\"\"\"\n",
    "    fits = lc.fit\n",
    "    flux = fits.apply(lambda f: f.flux)\n",
    "    errors = fits.apply(lambda f: (round(f.errors[0]-f.flux,3), round(f.errors[1]-f.flux ,3) ) )\n",
    "    sigma_dev = fits.apply(lambda f: round(f.poiss.sigma_dev(expect),1) )\n",
    "    df = lc['t tw n'.split()].copy() # maybe fix warnings?\n",
    "    df.loc[:,'flux'] = flux.values.round(4)\n",
    "    df.loc[:, 'errors'] = errors.values\n",
    "    df.loc[:, 'sigma_dev'] = sigma_dev.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=Config(cachepath='/tmp/cache2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell data for PSR_B1259-63: Restoring from cache with key \"cells_PSR_B1259-63\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Fit to all data\n",
       "\n",
       "Combine the likelihoods for all the data, check the fit.\n",
       "This defines the base normalization.\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 1\">  <a href=\"images/peri_fig_01.png\" title=\"images/peri_fig_01.png\">    <img src=\"images/peri_fig_01.png\" alt=\"Figure 1 at images/peri_fig_01.png\" >   </a> </figure>\n",
       "</div>\n",
       "\n",
       "\n",
       "### The full light curve, showing the BB partitions\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 2\">  <a href=\"images/peri_fig_02.png\" title=\"images/peri_fig_02.png\">    <img src=\"images/peri_fig_02.png\" alt=\"Figure 2 at images/peri_fig_02.png\" width=600>   </a> </figure>\n",
       "</div>\n",
       "\n",
       "### Periastron dates\n",
       "Assuming 1237-day orbital period, the MJD and UTC values are:\n",
       "\n",
       "<p style=\"margin-left: 5%\"><samp>{ 55546: '2010-12-16 00:00',\n",
       "  56783: '2014-05-06 00:00',\n",
       "  58020: '2017-09-24 00:00',\n",
       "  59257: '2021-02-12 00:00'}</samp></p>\n",
       "\n",
       "Expand the above about those dates\n",
       "\n",
       "<div class=\"nbdoc_image\">\n",
       "<figure style=\"margin-left: 5%\" title=\"Figure 3\">  <a href=\"images/peri_fig_03.png\" title=\"images/peri_fig_03.png\">    <img src=\"images/peri_fig_03.png\" alt=\"Figure 3 at images/peri_fig_03.png\" >   </a> </figure>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<utilities.ipynb_docgen.doc_formatter.<locals>.MimeBundleObject at 0x7f483635dd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "bb_lc = None\n",
    "lc = None\n",
    "def peri(name='PSR_B1259-63', expect=1):\n",
    "    \"\"\"\n",
    "    ## Fit to all data\n",
    "    \n",
    "    Combine the likelihoods for all the data, check the fit.\n",
    "    This defines the base normalization.\n",
    "    {fig1}\n",
    "    \n",
    "    ### The full light curve, showing the BB partitions\n",
    "    {fig2}\n",
    "    ### Periastron dates\n",
    "    Assuming {p}-day orbital period, the MJD and UTC values are:\n",
    "    \n",
    "    {utc}\n",
    "    \n",
    "    Expand the above about those dates\n",
    "    \n",
    "    {fig3}\n",
    "    \"\"\"\n",
    "    global lc, bb_lc\n",
    "    \n",
    "    plt.rc('font', size=14)\n",
    "    source = PointSource(name)\n",
    "    cells = get_cells(config, source)\n",
    "    cell = concatenate_cells(cells)\n",
    "    \n",
    "\n",
    "    ll = LogLike(cell); \n",
    "    #print(ll,'\\nFit: ', ll.fit_info())\n",
    "    fig1, ax1 = plt.subplots(num=1, figsize=(3,2))\n",
    "    ll.plot(xlim =( 0.5, 1.5), ax=ax1)\n",
    "   \n",
    "    with capture_print('Analysis output') as outp:\n",
    "        lc, bb_lc = analyze_data(config, source)\n",
    "        \n",
    "    pd.set_option('display.precision', 3)#, 'display.colheader_justify','left')\n",
    "    \n",
    "    df = fit_table(bb_lc, expect=expect)\n",
    "    df_text = monospace(str(df), 'BB fit table', open=True)\n",
    "        \n",
    "    plt.rc('font', size=16)\n",
    "    fig2, ax2 = plt.subplots(1,1, sharex=True, figsize=(20,4), num=2)\n",
    "    bb_overplot(config, lc, bb_lc, ax = ax2)\n",
    "    ax2.text(0.05, 0.85, name,  transform=ax2.transAxes);\n",
    "    ax2.set(yscale='log')\n",
    "    fig2.width=600\n",
    "    \n",
    "    tp=55546\n",
    "    p = 1237\n",
    "    utc = dict((tp+n*p, UTC(tp+n*p)) for n in range(4))\n",
    "    \n",
    "    fig3, axx = plt.subplots(3,1, sharex=False, sharey=True, figsize=(12,12), num=3)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    for i, ax in enumerate(axx.flatten()):\n",
    "        bb_overplot(config, lc, bb_lc, ax=ax, tzero=tp+i*p, xlim=(-30,90), yscale='log', colors=('black','wheat','blue'))\n",
    "        ax.text(0.02, 0.9, UTC(tp+i*p)[:4], transform=ax.transAxes)\n",
    "    return locals()\n",
    "nbdoc(peri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a light curve summary\n",
    "\n",
    "Save the csv file [here](images/B1259_lc.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "lc_out = bb_lc.copy()\n",
    "\n",
    "lc_out.loc[:,'flux'] = bb_lc.fit.apply(lambda fit: round(fit.flux,3))\n",
    "errors = bb_lc.fit.apply(lambda fit: np.array(fit.errors).round(3)).values\n",
    "elow, ehigh = [[x[i] for x in errors] for i in range(2)]\n",
    "lc_out['low']=elow\n",
    "lc_out['high']=ehigh\n",
    "lc_out['t tw n flux low high'.split()].to_csv('images/B1259_lc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "def bb_overplot(config, lc, bb_fit, ax=None,  **kwargs):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12,4)) if not ax else (ax.figure, ax)\n",
    "    flux_plot(config, lc, ax=ax, colors=(('lightblue', 'sandybrown', 'blue')),**kwargs)\n",
    "    flux_plot(config, bb_fit, ax=ax, step=True, **kwargs)\n",
    "    \n",
    "def simulation(config, source, bb_key=None):\n",
    "    \"\"\"Create and analyze a simulation for the source\n",
    "    Returns the simulated, and fit light curves\n",
    "    \"\"\"\n",
    "\n",
    "    lc = get_lightcurve(config, source)\n",
    "    data_cells = get_cells(config, source)\n",
    "\n",
    "    #  Get the rate from the data\n",
    "    cq = data_cells.query('e>0.3')\n",
    "    T, N = np.sum(cq.tw), np.sum(cq.n)\n",
    "    sflux=lambda t: N/T\n",
    "\n",
    "    # simulate, then fit cells to create a simulated light curve \n",
    "    sim_cells = simulate_cells(config, source, source_flux=sflux  )\n",
    "    sim_lc  = fit_cells(config, sim_cells) \n",
    "\n",
    "    sim_edges = get_bb_partition(config, sim_lc,  key=bb_key) #'simulated_BB_partition_Geminga') \n",
    "\n",
    "    # partion, then fit the cells according to the edges\n",
    "    sim_bb_cells = partition_cells(config, sim_cells, sim_edges);\n",
    "    sim_bb_fit  = fit_cells(config, sim_bb_cells, )\n",
    "    return sim_lc, sim_bb_fit\n",
    "\n",
    "def analyze_data(config, source):\n",
    "    \"\"\"\n",
    "    Analyze data from the source\n",
    "    \n",
    "    Returns, data a partitioned light curves\n",
    "    \"\"\"\n",
    "    lc = get_lightcurve(config, source)\n",
    "    cells = get_cells(config, source)\n",
    "    edges = get_bb_partition(config, lc, LikelihoodFitness, key='bb-Geminga-test') \n",
    "    bb_cells = partition_cells(config, cells, edges);\n",
    "    bb_lc  = fit_cells(config, bb_cells, )\n",
    "    return lc, bb_lc\n",
    "\n",
    "def fit_table(lc, expect=1.0):\n",
    "    \"\"\"Generate a summary table from a light curve\"\"\"\n",
    "    fits = lc.fit\n",
    "    flux = fits.apply(lambda f: f.flux)\n",
    "    errors = fits.apply(lambda f: (round(f.errors[0]-f.flux,3), round(f.errors[1]-f.flux ,3) ) )\n",
    "    sigma_dev = fits.apply(lambda f: round(f.poiss.sigma_dev(expect),1) )\n",
    "    df = lc['t tw n'.split()].copy() # maybe fix warnings?\n",
    "    df.loc[:,'flux'] = flux.values.round(4)\n",
    "    df.loc[:, 'errors'] = errors.values\n",
    "    df.loc[:, 'sigma_dev'] = sigma_dev.values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
