{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exposure\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure\n",
    "> calculate exposure for a point source from a GTI and FT2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import simps\n",
    "from light_curves.config import MJD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _process_ft2(config, source, ft2_file_path, gti, effective_area):\n",
    "    \"\"\"Process a set of FT2 files, with S/C history data\n",
    "    Parameters:\n",
    "        - config -- verbose, cos_theta_max, z_max\n",
    "        - source -- l,b for position\n",
    "        - ft2_files -- list of spacecraft files\n",
    "        - gti -- GTI object with allowed intervals\n",
    "        - effective_area -- function of energy and angle with respect to zenity\n",
    "    Generate a dataset with fields:\n",
    "        - start, stop : start  and stop times in MJD\n",
    "        - exposure    : calculated exposure using effective area\n",
    "\n",
    "     \"\"\"\n",
    "    # combine the files into a DataFrame with following fields besides START and STOP (lower case for column)\n",
    "    fields    = ['LIVETIME','RA_SCZ','DEC_SCZ', 'RA_ZENITH','DEC_ZENITH']\n",
    "    ft2_files = list(ft2_file_path.glob('*.fits'))\n",
    "    if config.verbose>1:\n",
    "        print(f'Processing {len(ft2_files)} S/C history (FT2) files')\n",
    "        print(f'  applying cuts cos(theta) < {config.cos_theta_max},  z < {config.z_max}')\n",
    "    sc_data=[]\n",
    "    for filename in ft2_files:\n",
    "        with fits.open(filename) as hdu:\n",
    "            scdata = hdu['SC_DATA'].data\n",
    "            # get times to check against MJD limits and GTI\n",
    "            start, stop = [MJD(np.array(scdata.START, float)),\n",
    "                           MJD(np.array(scdata.STOP, float))]\n",
    "            if config.mjd_range is not None:\n",
    "                a,b=  config.mjd_range\n",
    "                if stop[-1]<a:\n",
    "                    print(f'\\tfile {filename}: skip, before selected range' )\n",
    "                    continue\n",
    "                elif start[0]>b:\n",
    "                    print(f'\\tfile {filename}: quit, beyond range')\n",
    "                    break\n",
    "            # apply GTI to bin center (avoid edge effects?)\n",
    "            in_gti = gti(0.5*(start+stop))\n",
    "            if config.verbose>2:\n",
    "                print(f'\\tfile {filename}: {len(start)} entries, {sum(in_gti)} in GTI')\n",
    "            t = [('start', start[in_gti]), ('stop',stop[in_gti])]+\\\n",
    "                [(field.lower(), np.array(scdata[field][in_gti],np.float32)) for field in fields ]\n",
    "            sc_data.append( pd.DataFrame(dict(t) ) )\n",
    "    df = pd.concat(sc_data, ignore_index=True)\n",
    "\n",
    "    # calculate cosines with respect to sky direction\n",
    "    sc = source\n",
    "    ra_r,dec_r = np.radians(sc.ra), np.radians(sc.dec)\n",
    "    sdec, cdec = np.sin(dec_r), np.cos(dec_r)\n",
    "\n",
    "    def cosines( ra2, dec2):\n",
    "        ra2_r =  np.radians(ra2.values)\n",
    "        dec2_r = np.radians(dec2.values)\n",
    "        return np.cos(dec2_r)*cdec*np.cos(ra_r-ra2_r) + np.sin(dec2_r)*sdec\n",
    "\n",
    "    pcosines = cosines(df.ra_scz,    df.dec_scz)\n",
    "    zcosines = cosines(df.ra_zenith, df.dec_zenith)\n",
    "\n",
    "    # mask out entries too close to zenith, or too far away from ROI center\n",
    "    mask =   (pcosines >= config.cos_theta_max) & (zcosines>=np.cos(np.radians(config.z_max)))\n",
    "    if config.verbose>1:\n",
    "        print(f'\\tFound {len(mask):,} S/C entries:  {sum(mask):,} remain after zenith and theta cuts')\n",
    "    dfm = df.loc[mask,:]\n",
    "    livetime = dfm.livetime.values\n",
    "    config.dfm = dfm ##############debug\n",
    "    # apply MJD range if present. note times in MJD\n",
    "    start, stop = dfm.start,dfm.stop\n",
    "    lims = slice(None)\n",
    "    if config.mjd_range is not None:\n",
    "#         a, b = config._get_limits(start)\n",
    "        a, b = np.searchsorted(start, config.mjd_range)\n",
    "        if a>0 or b<len(start):\n",
    "            if config.verbose>1:\n",
    "                print(f'\\tcut from {len(start):,} to {a} - {b}, or {b-a:,} entries after MJD range selection')\n",
    "            dfm = dfm.iloc[a:b]\n",
    "            lims = slice(a,b)\n",
    "\n",
    "\n",
    "    expose = _exposure(config, effective_area, livetime[lims], pcosines[mask][lims])\n",
    "    return pd.DataFrame(dict(start=start[lims],stop=stop[lims], exposure=expose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _exposure(config, effective_area, livetime, pcosine):\n",
    "    \"\"\"return exposure calculated for each pair in livetime and cosines arrays\n",
    "\n",
    "    uses effective area\n",
    "    \"\"\"\n",
    "    assert len(livetime)==len(pcosine), 'expect equal-length arrays'\n",
    "\n",
    "    # get a set of energies and associated weights from a trial spectrum\n",
    "\n",
    "    emin,emax = config.energy_range\n",
    "    loge1=np.log10(emin); loge2=np.log10(emax)\n",
    "\n",
    "    edom=np.logspace(loge1, loge2, int((loge2-loge1)*config.bins_per_decade+1))\n",
    "    if config.verbose>1:\n",
    "        print(f'Calculate exposure using the energy domain'\\\n",
    "              f' {emin}-{emax} {config.bins_per_decade} bins/decade' )\n",
    "    base_spectrum = eval(config.base_spectrum) #lambda E: (E/1000)**-2.1\n",
    "    assert base_spectrum(1000)==1.\n",
    "    wts = base_spectrum(edom)\n",
    "\n",
    "    # effectivee area function from\n",
    "    ea = effective_area\n",
    "\n",
    "    # a table of the weighted for each pair in livetime and pcosine arrays\n",
    "    rvals = np.empty([len(wts),len(pcosine)])\n",
    "    for i,(en,wt) in enumerate(zip(edom,wts)):\n",
    "        faeff,baeff = ea([en],pcosine)\n",
    "        rvals[i] = (faeff+baeff)*wt\n",
    "\n",
    "    aeff = simps(rvals,edom,axis=0)/simps(wts,edom)\n",
    "    return (aeff*livetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_exposure(config, files, gti, source, use_cache=True):\n",
    "    \"\"\"Return the exposure for the source\n",
    "    If gti is None, regenerate it\n",
    "    \"\"\"\n",
    "    from  light_curves.load_gti import get_gti\n",
    "    from light_curves.effective_area import EffectiveArea\n",
    "    \n",
    "    fcache = files.cache/f'{source.filename}_exposure.pkl' if use_cache else None\n",
    "\n",
    "    if fcache and fcache.exists():    \n",
    "        if config.verbose>1:\n",
    "            print(f'restoring exposure from {fcache} ' , end='')\n",
    "        exposure = pd.read_pickle(fcache)\n",
    "        if config.verbose>1:\n",
    "            print(f'{len(exposure)} entries, MJD {exposure.iloc[0].start:.0f}'\n",
    "                  f' - {exposure.iloc[-1].stop:.0f}')\n",
    "            \n",
    "    else:\n",
    "        gti = gti or get_gti(config, files.gti)\n",
    "        aeff = EffectiveArea(file_path = files.aeff)\n",
    "        exposure =  _process_ft2(config, source, files.ft2, gti, aeff)\n",
    "\n",
    "        if fcache:\n",
    "            if config.verbose>1:\n",
    "                print(f'saving exposure to {fcache}')\n",
    "            exposure.to_pickle(fcache)\n",
    "    return exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 11 FITS files with GTI information ...  11 files, 63635 intervals with 3,322 days live time\n",
      "\tGTI MJD range: 54682.66-58698.08, good fraction 0.83 \n",
      "Processing 12 S/C history (FT2) files\n",
      "  applying cuts cos(theta) < 0.4,  z < 100\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2008.fits: 362996 entries, 360944 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2009.fits: 874661 entries, 870446 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2010.fits: 889547 entries, 884697 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2011.fits: 882832 entries, 871672 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2012.fits: 881317 entries, 868109 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2013.fits: 885307 entries, 867342 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2014.fits: 894730 entries, 886570 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2015.fits: 890006 entries, 886086 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2016.fits: 890933 entries, 884823 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2017.fits: 888349 entries, 883761 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2018.fits: 842824 entries, 830723 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2019.fits: 737029 entries, 514657 in GTI\n",
      "\tFound 9,609,830 S/C entries:  2,695,715 remain after zenith and theta cuts\n",
      "Calculate exposure using the energy domain 100.0-1000000.0 4 bins/decade\n",
      "saving exposure to /tmp/light_curves/Geminga_exposure.pkl\n"
     ]
    }
   ],
   "source": [
    "from light_curves.config import Config, Files, PointSource\n",
    "files = Files()\n",
    "config=Config()\n",
    "source = PointSource('Geminga')\n",
    "\n",
    "exposure = get_exposure(config, files, None, source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a tuple of time intervals and the exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                start          stop       exposure\n",
      "0        54682.656038  54682.656375  112998.052089\n",
      "1        54682.656375  54682.656722  116901.160578\n",
      "2        54682.656722  54682.657069  116857.143435\n",
      "3        54682.657069  54682.657416  116791.434285\n",
      "4        54682.657416  54682.657764  116876.550059\n",
      "...               ...           ...            ...\n",
      "9609753  58698.052602  58698.052949   52427.727986\n",
      "9609754  58698.052949  58698.053296   49343.687807\n",
      "9609755  58698.053296  58698.053643   44567.360241\n",
      "9609756  58698.053643  58698.053991   38779.120217\n",
      "9609757  58698.053991  58698.054338   31786.491045\n",
      "\n",
      "[2695715 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if exposure is not None:\n",
    "    print(exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
