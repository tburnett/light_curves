{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exposure\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposure\n",
    "> calculate exposure for a point source from a GTI and FT2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import simps\n",
    "from light_curves.config import MJD, Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _process_ft2(config, source, ft2_file_path, gti, effective_area):\n",
    "    \"\"\"Process a set of FT2 files, with S/C history data\n",
    "    Parameters:\n",
    "        - config -- verbose, cos_theta_max, z_max\n",
    "        - source -- l,b for position\n",
    "        - ft2_files -- list of spacecraft files\n",
    "        - gti -- GTI object with allowed intervals\n",
    "        - effective_area -- function of energy and angle with respect to zenity\n",
    "    Generate a dataset with fields:\n",
    "        - start, stop : start  and stop times in MJD\n",
    "        - exposure    : calculated exposure using effective area\n",
    "\n",
    "     \"\"\"\n",
    "    # combine the files into a DataFrame with following fields besides START and STOP (lower case for column)\n",
    "    fields    = ['LIVETIME','RA_SCZ','DEC_SCZ', 'RA_ZENITH','DEC_ZENITH']\n",
    "    ft2_files = list(ft2_file_path.glob('*.fits'))\n",
    "    if config.verbose>1:\n",
    "        print(f'Processing {len(ft2_files)} S/C history (FT2) files')\n",
    "        print(f'  applying cuts cos(theta) < {config.cos_theta_max},  z < {config.z_max}')\n",
    "    sc_data=[]\n",
    "    for filename in ft2_files:\n",
    "        with fits.open(filename) as hdu:\n",
    "            scdata = hdu['SC_DATA'].data\n",
    "            # get times to check against MJD limits and GTI\n",
    "            start, stop = [MJD(np.array(scdata.START, float)),\n",
    "                           MJD(np.array(scdata.STOP, float))]\n",
    "            if config.mjd_range is not None:\n",
    "                a,b=  config.mjd_range\n",
    "                if stop[-1]<a:\n",
    "                    print(f'\\tfile {filename}: skip, before selected range' )\n",
    "                    continue\n",
    "                elif start[0]>b:\n",
    "                    print(f'\\tfile {filename}: quit, beyond range')\n",
    "                    break\n",
    "            # apply GTI to bin center (avoid edge effects?)\n",
    "            in_gti = gti(0.5*(start+stop))\n",
    "            if config.verbose>2:\n",
    "                print(f'\\tfile {filename}: {len(start)} entries, {sum(in_gti)} in GTI')\n",
    "            t = [('start', start[in_gti]), ('stop',stop[in_gti])]+\\\n",
    "                [(field.lower(), np.array(scdata[field][in_gti],np.float32)) for field in fields ]\n",
    "            sc_data.append( pd.DataFrame(dict(t) ) )\n",
    "    df = pd.concat(sc_data, ignore_index=True)\n",
    "\n",
    "    # calculate cosines with respect to sky direction\n",
    "    sc = source\n",
    "    ra_r,dec_r = np.radians(sc.ra), np.radians(sc.dec)\n",
    "    sdec, cdec = np.sin(dec_r), np.cos(dec_r)\n",
    "\n",
    "    def cosines( ra2, dec2):\n",
    "        ra2_r =  np.radians(ra2.values)\n",
    "        dec2_r = np.radians(dec2.values)\n",
    "        return np.cos(dec2_r)*cdec*np.cos(ra_r-ra2_r) + np.sin(dec2_r)*sdec\n",
    "\n",
    "    pcosines = cosines(df.ra_scz,    df.dec_scz)\n",
    "    zcosines = cosines(df.ra_zenith, df.dec_zenith)\n",
    "\n",
    "    # mask out entries too close to zenith, or too far away from ROI center\n",
    "    mask =   (pcosines >= config.cos_theta_max) & (zcosines>=np.cos(np.radians(config.z_max)))\n",
    "    if config.verbose>1:\n",
    "        print(f'\\tFound {len(mask):,} S/C entries:  {sum(mask):,} remain after zenith and theta cuts')\n",
    "    dfm = df.loc[mask,:]\n",
    "    livetime = dfm.livetime.values\n",
    "    config.dfm = dfm ##############debug\n",
    "    # apply MJD range if present. note times in MJD\n",
    "    start, stop = dfm.start,dfm.stop\n",
    "    lims = slice(None)\n",
    "    if config.mjd_range is not None:\n",
    "#         a, b = config._get_limits(start)\n",
    "        a, b = np.searchsorted(start, config.mjd_range)\n",
    "        if a>0 or b<len(start):\n",
    "            if config.verbose>1:\n",
    "                print(f'\\tcut from {len(start):,} to {a} - {b}, or {b-a:,} entries after MJD range selection')\n",
    "            dfm = dfm.iloc[a:b]\n",
    "            lims = slice(a,b)\n",
    "\n",
    "\n",
    "    expose = _exposure(config, effective_area, livetime[lims], pcosines[mask][lims])\n",
    "    return pd.DataFrame(dict(start=start[lims],stop=stop[lims], exposure=expose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _exposure(config, effective_area, livetime, pcosine):\n",
    "    \"\"\"return exposure calculated for each pair in livetime and cosines arrays\n",
    "\n",
    "    uses effective area\n",
    "    \"\"\"\n",
    "    assert len(livetime)==len(pcosine), 'expect equal-length arrays'\n",
    "\n",
    "    # get a set of energies and associated weights from a trial spectrum\n",
    "\n",
    "    emin,emax = config.energy_range\n",
    "    loge1=np.log10(emin); loge2=np.log10(emax)\n",
    "\n",
    "    edom=np.logspace(loge1, loge2, int((loge2-loge1)*config.bins_per_decade+1))\n",
    "    if config.verbose>1:\n",
    "        print(f'Calculate exposure using the energy domain'\\\n",
    "              f' {emin}-{emax} {config.bins_per_decade} bins/decade' )\n",
    "    base_spectrum = eval(config.base_spectrum) #lambda E: (E/1000)**-2.1\n",
    "    assert base_spectrum(1000)==1.\n",
    "    wts = base_spectrum(edom)\n",
    "\n",
    "    # effectivee area function from\n",
    "    ea = effective_area\n",
    "\n",
    "    # a table of the weighted for each pair in livetime and pcosine arrays\n",
    "    rvals = np.empty([len(wts),len(pcosine)])\n",
    "    for i,(en,wt) in enumerate(zip(edom,wts)):\n",
    "        faeff,baeff = ea([en],pcosine)\n",
    "        rvals[i] = (faeff+baeff)*wt\n",
    "\n",
    "    aeff = simps(rvals,edom,axis=0)/simps(wts,edom)\n",
    "    return (aeff*livetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_exposure(config,  source, gti_key='gti'):\n",
    "    \"\"\"Return the exposure for the source\n",
    "\n",
    "    \"\"\"\n",
    "    from  light_curves.load_gti import get_gti\n",
    "    from light_curves.effective_area import EffectiveArea\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    def getit():\n",
    "        files = config.files\n",
    "   \n",
    "        gti = get_gti(config, gti_key)\n",
    "        aeff = EffectiveArea(file_path = files.aeff)\n",
    "        exposure =  _process_ft2(config, source, files.ft2, gti, aeff)\n",
    "        if config.verbose>1:\n",
    "            print(f'{len(exposure)} entries, MJD {exposure.iloc[0].start:.0f}'\n",
    "                  f' - {exposure.iloc[-1].stop:.0f}')\n",
    "        return exposure\n",
    "    \n",
    "    key = f'exposure_{source.name}'\n",
    "    if config.verbose>1: \n",
    "        print(f'using cache with key \"{key}\", exists: {key in config.cache}')\n",
    "    return config.cache(key, getit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get, and display the exposure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a tuple of time intervals and the exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cache with key \"exposure_Geminga\", exists: True\n",
      "Exposure for Geminga:\n",
      "                 start          stop       exposure\n",
      "0        54682.656038  54682.656375  112998.052089\n",
      "1        54682.656375  54682.656722  116901.160578\n",
      "2        54682.656722  54682.657069  116857.143435\n",
      "3        54682.657069  54682.657416  116791.434285\n",
      "4        54682.657416  54682.657764  116876.550059\n",
      "...               ...           ...            ...\n",
      "9609753  58698.052602  58698.052949   52427.727986\n",
      "9609754  58698.052949  58698.053296   49343.687807\n",
      "9609755  58698.053296  58698.053643   44567.360241\n",
      "9609756  58698.053643  58698.053991   38779.120217\n",
      "9609757  58698.053991  58698.054338   31786.491045\n",
      "\n",
      "[2695715 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from light_curves.config import Config,  PointSource, Cache\n",
    "config = Config()\n",
    "source = PointSource('Geminga')\n",
    "\n",
    "if config.valid:\n",
    "    exposure = get_exposure(config, source)  \n",
    "    print(f'Exposure for {source.name}:\\n {exposure}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from light_curves.config import day\n",
    "def get_contiguous_exposure(exposure, max_interval=10, verbose=0 ):\n",
    "    \"\"\"Combine exposure intervals from an exposure dataframe\n",
    "    return array of (start, stop) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    t0s = exposure.start.values\n",
    "    t1s = exposure.stop.values\n",
    "    break_mask = (t0s[1:]-t1s[:-1])>max_interval/day \n",
    "    break_starts = t1s[:-1][break_mask]\n",
    "    break_stops = t0s[1:][break_mask]\n",
    "    # now assumble the complement\n",
    "    good_starts = np.empty(len(break_starts)+1)\n",
    "    good_stops = np.empty_like(good_starts)\n",
    "    good_starts[0] = t0s[0]\n",
    "    good_starts[1:] = break_stops\n",
    "    good_stops[-1] = t1s[-1]\n",
    "    good_stops[:-1] = break_starts\n",
    "    if verbose>1:\n",
    "        print(f'Generate list of contiguous exposures:\\n'\\\n",
    "              f'  WIth max interval {max_interval} s, combine {len(t0s):,} exposure entries to {len(good_stops):,} ')\n",
    "    return np.array([good_starts, good_stops]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate list of contiguous exposures:\n",
      "  WIth max interval 10 s, combine 2,695,715 exposure entries to 61,561 \n",
      "Check exposures in hours, gap:  0.02-751.07  delta: 0.00- 0.93\n"
     ]
    }
   ],
   "source": [
    "# #hide\n",
    "if config.valid:\n",
    "    expsub = exposure#.iloc[:1000]\n",
    "    ec = get_contiguous_exposure(expsub, verbose=2)\n",
    " \n",
    "    a, b  = ec[:,0], ec[:,1]\n",
    "    gap = b[1:]-a[:-1]\n",
    "\n",
    "    delta = (b-a)\n",
    "    print(f'Check exposures in hours, gap:  {gap.min()*24:.2f}-{gap.max()*24:.2f}'\\\n",
    "          f'  delta: {delta.min()*24:.2f}- {delta.max()*24:.2f}')\n",
    "    #plt.hist(delta*24*60, np.linspace(0,40,21));\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_poisson.ipynb.\n",
      "Converted 09_simulation.ipynb.\n",
      "Converted 10_loglike.ipynb.\n",
      "Converted 11_lightcurve.ipynb.\n",
      "Converted 12_roadmap.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Sat Dec 19 06:14:17 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
