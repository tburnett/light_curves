{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp lightcurve\n",
    "%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Curve\n",
    "> Generate light curves from cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from utilities import  keyword_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cells with source Geminga \n",
      "Processing 11 GTI files ...  11 files, 63635 intervals with 3,322 days live time\n",
      "\tGTI MJD range: 54682.66-58698.08, good fraction 0.83 \n",
      "Loading  132 months from Arrow dataset /home/burnett/data/dataset\n",
      "....................................................................................................................................\n",
      "\tSelected 1313726 photons within 5 deg of  (195.13,4.27)\n",
      "\tEnergies: 100.0-1000000 MeV\n",
      "\tDates:    2008-08-04 15:46 - 2019-08-03 01:17\n",
      "\tMJD  :    54682.7          - 58698.1         \n",
      "Load weights from file /mnt/c/users/thbur/OneDrive/fermi/weight_files/Geminga_weights.pkl\n",
      "\tFound: PSR J0633+1746 at (195.14, 4.27)\n",
      "\tApplyng weights: 240 / 1313726 photon pixels are outside weight region\n",
      "\t233109 weights set to NaN\n",
      "Processing 11 GTI files ...  11 files, 63635 intervals with 3,322 days live time\n",
      "\tGTI MJD range: 54682.66-58698.08, good fraction 0.83 \n",
      "Processing 12 S/C history (FT2) files\n",
      "  applying cuts cos(theta) < 0.4,  z < 100\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2008.fits: 362996 entries, 360944 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2009.fits: 874661 entries, 870446 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2010.fits: 889547 entries, 884697 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2011.fits: 882832 entries, 871672 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2012.fits: 881317 entries, 868109 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2013.fits: 885307 entries, 867342 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2014.fits: 894730 entries, 886570 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2015.fits: 890006 entries, 886086 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2016.fits: 890933 entries, 884823 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2017.fits: 888349 entries, 883761 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2018.fits: 842824 entries, 830723 in GTI\n",
      "\tfile /home/burnett/work/lat-data/ft2/ft2_2019.fits: 737029 entries, 514657 in GTI\n",
      "\tFound 9,609,830 S/C entries:  2,695,715 remain after zenith and theta cuts\n",
      "Calculate exposure using the energy domain 100.0-1000000.0 4 bins/decade\n",
      "Time bins: 4015 intervals of 1 days, in range (54683.0, 58698.0)\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from light_curves.config import LCconfig, FileConfiguration, PointSource\n",
    "from light_curves.binner import get_cells\n",
    "\n",
    "config = LCconfig()\n",
    "files = FileConfiguration()\n",
    "source = PointSource('Geminga')\n",
    "\n",
    "if files.valid:\n",
    "    print(f'Loading cells with source {source.name} ')\n",
    "    cells = get_cells(config, files, source)\n",
    "else:\n",
    "    print('Not testing since no files.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from light_curves.loglike import (GaussianRep, Gaussian2dRep, PoissonRep, PoissonRepTable)\n",
    "\n",
    "class LightCurve(object):\n",
    "    \"\"\" In the language of Kerr, manage a set of cells\n",
    "    \"\"\"\n",
    "    defaults=(\n",
    "        ('min_exp', 0.3, 'mimimum exposure factor'),\n",
    "        ('rep',   'poisson', 'name of the likelihood representation: poisson, gauss, or gauss2d'),\n",
    "        ('replist', 'gauss gauss2d poisson poisson_table'.split(), 'Possible reps'),\n",
    "        ('rep_class', [GaussianRep, Gaussian2dRep, PoissonRep, PoissonRepTable], 'coresponding classes'),\n",
    "        ('verbose', 0, 'verbosity'),\n",
    "    )\n",
    "    @keyword_options.decorate(defaults)\n",
    "    def __init__(self, binned_weights, **kwargs):\n",
    "        \"\"\"Load binned data\n",
    "        parameters:\n",
    "            binned_weights : an iterable object that is a list of dicts; expect each\n",
    "                to have following keys:\n",
    "                    t, tw, fexp, w, S, B\n",
    "            min_exp : minimum fractional exposure allowed\n",
    "        \"\"\"\n",
    "        keyword_options.process(self,kwargs)\n",
    "        global data\n",
    "        self.data=data=binned_weights.data\n",
    "        self.source_name = self.data.source_name\n",
    "        self.verbose = getattr(data, 'verbose', self.verbose)\n",
    "\n",
    "        # select the set of cells\n",
    "        self.cells = [LogLike(ml) for ml in binned_weights if ml['fexp']>self.min_exp]\n",
    "        if self.verbose>0:\n",
    "            print(f'Loaded {len(self)} / {len(binned_weights)} cells with exposure >'\\\n",
    "                  f' {self.min_exp} for light curve analysis')\n",
    "\n",
    "        # analyze using selected rep\n",
    "        if self.rep not in self.replist:\n",
    "            raise Exception(f'Unrecognized rep: \"{self.rep}\", must be one of {self.replist}')\n",
    "        repcl = self.rep_class[self.replist.index(self.rep)]\n",
    "\n",
    "        self.fit_df = self.fit(repcl)\n",
    "#         try:\n",
    "#             self.fit_df = self.fit(repcl)\n",
    "#         except Exception as msg:\n",
    "#             print(f'Fail fit: {msg} ') #'; stop here')\n",
    "#             raise Exception(msg)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}: source \"{self.source_name}\" fit with {len(self.fit_df)} cells'\n",
    "\n",
    "    def to_dict(self):\n",
    "        return dict(source_name=self.source_name,\n",
    "                    rep=self.rep,\n",
    "                    edges = self.data.edges,\n",
    "                    fit_dict = self.fit_df.to_dict('records'),\n",
    "               )\n",
    "\n",
    "\n",
    "    def write(self, filename):\n",
    "        with open(filename, 'wb') as out:\n",
    "            pickle.dump( self.to_dict(), out)\n",
    "\n",
    "            if self.verbose>0:\n",
    "                print(f'Wrote light curve for source \"{self.source_name}\" to {filename}')\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.cells[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cells)\n",
    "\n",
    "    def fit(self, repcl):\n",
    "        \"\"\"Perform fits to all intervals with chosen log likelihood representataon\n",
    "        \"\"\"\n",
    "        outd = dict()\n",
    "        for i, cell in enumerate(self):\n",
    "            try:\n",
    "                outd[i]=repcl(cell).fit\n",
    "            except Exception as msg:\n",
    "                print(f'{self.__class__}, {repcl} fail for Index {i}, LogLike {cell}\\n   {msg}')\n",
    "                raise\n",
    "\n",
    "        df = pd.DataFrame.from_dict(outd, orient='index', dtype=np.float32)\n",
    "        if self.verbose>0:\n",
    "            print(f'Fits using representation {self.rep}: {len(self)} intervals')\n",
    "            if self.verbose>1:\n",
    "                print(f'    columns: {list(df.columns)} ')\n",
    "        return df\n",
    "\n",
    "    @property\n",
    "    def dataframe(self):\n",
    "        \"\"\"return the summary DataFrame\n",
    "        \"\"\"\n",
    "        return self.fit_df\n",
    "\n",
    "    def create_tables(self, npts=100, support=1e-6):\n",
    "        \"\"\" create a set of tables representing the log-likelihoods of the cells\n",
    "        parameters:\n",
    "            npts : integer\n",
    "                number of points\n",
    "            support : float\n",
    "                Integral of the Likelihood PDF to discard on each end\n",
    "\n",
    "        returns\n",
    "            arrays for points and log-likelihood values as (N, npts) arraays\n",
    "        \"\"\"\n",
    "        assert self.rep.startswith('poisson'), 'Need a Poisson rep to calculate tables'\n",
    "        df = self.dataframe\n",
    "        dom = np.empty((len(df), npts), np.float32)\n",
    "        cod = np.empty((len(df), npts), np.float32)\n",
    "\n",
    "        def create_table(poiss):\n",
    "            # make a table of evently-spaced points between limits\n",
    "            a = poiss.cdfinv(support) if poiss.flux>0 else 0\n",
    "            b = poiss.cdfcinv(support)\n",
    "            x = np.linspace(a,b,npts).astype(np.float32)\n",
    "            y = np.array(list(map(poiss, x))) .astype(np.float32)\n",
    "            return x, y\n",
    "\n",
    "        for i,poiss in enumerate(map( poisson.Poisson, df.poiss_pars.values)):\n",
    "            dom[i], cod[i] = create_table(poiss)\n",
    "        return dom, cod\n",
    "\n",
    "    def flux_plot(self, ts_max=9, xerr=0.5, title=None, ax=None, **kwargs):\n",
    "        \"\"\"Make a plot of flux with according to the representation\n",
    "        \"\"\"\n",
    "        kw=dict(yscale='linear',xlabel='MJD', ylabel='relative flux',)\n",
    "        kw.update(**kwargs)\n",
    "        df=self.fit_df\n",
    "        if self.rep=='poisson':\n",
    "            ts = df.ts\n",
    "            limit = ts<ts_max\n",
    "            bar = df.loc[~limit,:]\n",
    "            lim = df.loc[limit,:]\n",
    "        else:\n",
    "            bar=df; lim=[]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,4)) if ax is None else (ax.figure, ax)\\\n",
    "            if ax is not None else (ax.figure,ax)\n",
    "\n",
    "        # the points with error bars\n",
    "        t = bar.t\n",
    "        xerr = bar.tw/2\n",
    "        y =  bar.flux.values\n",
    "        if self.rep=='poisson':\n",
    "            dy = [bar.errors.apply(lambda x: x[i]).clip(0,4) for i in range(2)]\n",
    "        elif self.rep=='gauss' or self.rep=='gauss2d':\n",
    "            dy = bar.sig_flux.clip(0,4)\n",
    "        else: assert False\n",
    "        ax.errorbar(x=t, y=y, xerr=xerr, yerr=dy, fmt=' ', color='silver')\n",
    "\n",
    "        # now do the limits\n",
    "        if len(lim)>0:\n",
    "            t = lim.t\n",
    "            xerr = lim.tw/2\n",
    "            y = lim.limit.values\n",
    "            yerr=0.2*(1 if kw['yscale']=='linear' else y)\n",
    "            ax.errorbar(x=t, y=y, xerr=xerr,\n",
    "                    yerr=yerr,  color='lightsalmon',\n",
    "                    uplims=True, ls='', lw=2, capsize=4, capthick=0,\n",
    "                    alpha=0.5)\n",
    "\n",
    "        #ax.axhline(1., color='grey')\n",
    "        ax.set(**kw)\n",
    "        ax.set_title(title or f'{self.source_name}, rep {self.rep}')\n",
    "        ax.grid(alpha=0.5)\n",
    "\n",
    "    def fit_hists(self, title=None, fignum=None, **hist_kw):\n",
    "        \"\"\"### Plot distributions of rate, error, pull\n",
    "\n",
    "        Source name:  \"{source_name}\"\n",
    "        Bins fit with {self.rep} model.\n",
    "\n",
    "        {fig.html}\n",
    "\n",
    "        \"\"\"\n",
    "        source_name=self.source_name\n",
    "        hkw = dict(log=True, histtype='stepfilled',lw=2, edgecolor='blue', facecolor='lightblue')\n",
    "        hkw.update(hist_kw)\n",
    "\n",
    "        df = self.fit_df\n",
    "        fig, (ax1,ax2,ax3)= plt.subplots(1,3, figsize=(10,3.0), tight_layout=True, num=fignum)\n",
    "        x = df.t\n",
    "        y = df.flux\n",
    "        if self.rep=='poisson': #mean of high, low\n",
    "            yerr = df.errors.apply(lambda x: (x[0]+x[1])/2).clip(0,4)\n",
    "        elif self.rep=='gauss' or self.rep=='gauss2d':\n",
    "            yerr = df.sig_flux.clip(0,4)\n",
    "        else: assert False\n",
    "\n",
    "        def shist(ax, x,  xlim, nbins, label, xlog=False):\n",
    "            def space(xlim, nbins=50):\n",
    "                if xlog:\n",
    "                    return np.logspace(np.log10(xlim[0]), np.log10(xlim[1]))\n",
    "                return np.linspace(xlim[0], xlim[1], nbins+1)\n",
    "            info = f'mean {x.mean():6.3f}\\nstd  {x.std():6.3f}'\n",
    "            ax.hist(x.clip(*xlim), bins=space(xlim, nbins), **hkw)\n",
    "            ax.set(xlabel=label, xscale='log' if xlog else 'linear', ylim=(0.8,None))\n",
    "            ax.text(0.62, 0.82, info, transform=ax.transAxes,fontdict=dict(size=10, family='monospace'))\n",
    "            ax.grid(alpha=0.5)\n",
    "            ax.xaxis.set_major_formatter(ticker.FuncFormatter(\n",
    "                lambda val,pos: { 1.0:'1', 10.0:'10', 100.:'100', 5:'5', -5:'-5'}.get(val,'')))\n",
    "            return ax\n",
    "\n",
    "        shist(ax1, y, (0.25, 4), 25, 'relative flux', xlog=True).axvline(1, color='grey')\n",
    "        shist(ax2, yerr*100, (1, 30), 25, 'sigma [%]', xlog=True)\n",
    "        shist(ax3, (y-1)/yerr, (-6,6), 25,'pull').axvline(0,color='grey')\n",
    "        return fig\n",
    "\n",
    "    def mean_std(self):\n",
    "        \"\"\" return weighted mean and rms\"\"\"\n",
    "        df = self.fit_df\n",
    "        frms = df.errors.apply(lambda err: 0.5*(err[0]+err[1]))\n",
    "        fwts = 1/frms**2\n",
    "        fmean = np.sum(df.flux*fwts)/np.sum(fwts)\n",
    "        t = (df.flux-fmean)/frms\n",
    "        return fmean, t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data to generate the light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
