{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp photon_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon Data\n",
    "\n",
    "> Load timed photon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks on loading the photon data around a source, subject to a GTI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os, sys\n",
    "import healpy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from light_curves.config import MJD, UTC\n",
    "from light_curves.load_gti import get_gti\n",
    "\n",
    "def get_photon_data(config: 'configuration data',\n",
    "#                     files:  'file locations',\n",
    "                    source: 'Source data',\n",
    "                    gti:   'Good Time Interval'=None,\n",
    "                    use_cache=True,\n",
    "                    nest=True):\n",
    "    \"\"\"\n",
    "    Read photon data from a Parquet dataset, select cone around the\n",
    "    source, use exposure to add exposures, return DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    def summarize(df):\n",
    "        emin,emax = config.energy_range or (config.energy_edges[0],config.energy_edges[-1])\n",
    "        print(f'\\n\\tSelected {len(df)} photons within {config.radius}'\\\n",
    "              f' deg of  ({source.l:.2f},{source.b:.2f})')\n",
    "        print(f'\\tEnergies: {emin:.1f}-{emax:.0f} MeV')\n",
    "        ta,tb = df.iloc[0].time, df.iloc[-1].time\n",
    "        print(f'\\tDates:    {UTC(ta):16} - {UTC(tb)}'\n",
    "            f'\\n\\tMJD  :    {ta:<16.1f} - {tb:<16.1f}')\n",
    "        \n",
    "    key = f'photons_{source.name}'\n",
    "    files = config.files\n",
    "    photon_data = config.cache.get(key)\n",
    "    if photon_data is not None:\n",
    "        if config.verbose>1: \n",
    "            print(f'restored {key} from cache')\n",
    "            summarize(photon_data)\n",
    "        return photon_data\n",
    "    \n",
    "    # check GTI\n",
    "    if gti is None:\n",
    "        gti = get_gti(config, files.gti)\n",
    "\n",
    "    # cone geometry stuff: get corresponding pixels and center vector\n",
    "    l,b,radius = source.l, source.b, config.radius\n",
    "    cart = lambda l,b: healpy.dir2vec(l,b, lonlat=True)\n",
    "    conepix = healpy.query_disc(config.nside, cart(l,b), np.radians(radius), nest=nest)\n",
    "    center = healpy.dir2vec(l,b, lonlat=True)\n",
    "\n",
    "    ebins = config.energy_edges\n",
    "    ecenters = np.sqrt(ebins[:-1]*ebins[1:]);\n",
    "    band_limits = 2*np.searchsorted(ecenters, config.energy_range) if config.energy_range is not None else None\n",
    "\n",
    "    def load_photon_data(table, tstart):\n",
    "        \"\"\"For a given month table, select photons in cone, add tstart to times,\n",
    "        return DataFrame with band, time, pixel, radius\n",
    "        \"\"\"\n",
    "        allpix = np.array(table.column('nest_index'))\n",
    "\n",
    "        def cone_select(allpix, conepix, shift=None):\n",
    "            \"\"\"Fast cone selection using NEST and shift\n",
    "            \"\"\"\n",
    "            if shift is None:\n",
    "                return np.isin(allpix, conepix)\n",
    "            assert nest, 'Expect pixels to use NEST indexing'\n",
    "            a = np.right_shift(allpix, shift)\n",
    "            c = np.unique(np.right_shift(conepix, shift))\n",
    "            return np.isin(a,c)\n",
    "\n",
    "        # a selection of all those in an outer cone\n",
    "        incone = cone_select(allpix, conepix, 13)\n",
    "\n",
    "        # times: convert to double, add to start, convert to MJD\n",
    "        time = MJD(np.array(table['time'],float)[incone]+tstart)\n",
    "        in_gti = gti(time)\n",
    "        if np.sum(in_gti)==0:\n",
    "            print(f'WARNING: no photons in GTI for month {month}!', file=sys.stderr)\n",
    "\n",
    "        pixincone = allpix[incone][in_gti]\n",
    "\n",
    "        # distance from center for all accepted photons\n",
    "        ll,bb = healpy.pix2ang(config.nside, pixincone,  nest=nest, lonlat=True)\n",
    "        cart = lambda l,b: healpy.dir2vec(l,b, lonlat=True)\n",
    "        t2 = np.degrees(np.array(np.sqrt((1.-np.dot(center, cart(ll,bb)))*2), np.float32))\n",
    "\n",
    "        # assemble the DataFrame, remove those outside the radius\n",
    "        out_df = pd.DataFrame(np.rec.fromarrays(\n",
    "            [np.array(table['band'])[incone][in_gti], time[in_gti], pixincone, t2],\n",
    "            names='band time pixel radius'.split()))\n",
    "\n",
    "        # apply final selection for radius and energy range\n",
    "\n",
    "        if band_limits is None: return out_df.query(f'radius<{radius}')\n",
    "\n",
    "        return out_df.query(f'radius<{radius} & {band_limits[0]} < band < {band_limits[1]}')\n",
    "\n",
    "    # get the monthly-partitioned dataset and tstart values\n",
    "    dataset = files.data/'dataset'\n",
    "    tstart_dict= pickle.load(open(files.data/'tstart.pkl', 'rb'))\n",
    "    months = tstart_dict.keys()\n",
    "\n",
    "    if config.verbose>0:\n",
    "        print(f'Loading  {len(months)} months from Arrow dataset {dataset}\\n', end='')\n",
    "\n",
    "    dflist=[]\n",
    "    for month, tstart in tstart_dict.items(): #months:\n",
    "        table= pq.read_table(dataset, filters=[f'month == {month}'.split()])\n",
    "        #tstart = tstart_dict[month]\n",
    "        d = load_photon_data(table, tstart)\n",
    "        if d is not None:\n",
    "            dflist.append(d)\n",
    "            if config.verbose>1: print('.', end='')\n",
    "        else:\n",
    "            if config.verbose>1: print('x', end='')\n",
    "            continue\n",
    "\n",
    "    assert len(dflist)>0, '\\nNo photon data found?'\n",
    "    df = pd.concat(dflist, ignore_index=True)\n",
    "    if config.verbose>0:\n",
    "        summarize(df)\n",
    "         \n",
    "\n",
    "    config.cache.add(key, df)\n",
    "    if config.verbose>1:\n",
    "        print(f'added {key} to cache')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loading a photon data set, for source Geminga\n",
      "restored photons_Geminga from cache\n",
      "\n",
      "\tSelected 1313726 photons within 5 deg of  (195.13,4.27)\n",
      "\tEnergies: 100.0-1000000 MeV\n",
      "\tDates:    2008-08-04 15:46 - 2019-08-03 01:17\n",
      "\tMJD  :    54682.7          - 58698.1         \n"
     ]
    }
   ],
   "source": [
    "from light_curves.config import Config,  PointSource\n",
    "\n",
    "config = Config()\n",
    "\n",
    "if config.valid:\n",
    "    source = PointSource('Geminga')\n",
    "\n",
    "    print(f'Test loading a photon data set, for source {source.name}')\n",
    "    photon_data = get_photon_data(config,  source )\n",
    "else:\n",
    "    print('Not testing since no files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "band      6.000000e+00\n",
       "time      5.468266e+04\n",
       "pixel     6.738278e+06\n",
       "radius    6.983809e-01\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photon_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/tmp/lc_cache')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.cache.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_load_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 09_poisson.ipynb.\n",
      "Converted 10_loglike.ipynb.\n",
      "Converted 11_lightcurve.ipynb.\n",
      "Converted 12_instructions.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Tue Dec 15 17:11:25 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
