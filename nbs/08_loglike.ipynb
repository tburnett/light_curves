{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp loglike\n",
    "%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Likelihood tools\n",
    "> Evaluate the Kerr likelihood, fits using poisson, gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Kerr likelihood formula  \n",
    "\n",
    "For each cell with a set of photons with weights $w$, the log likelihood as a function of $\\alpha$  and $\\beta$ is\n",
    "\n",
    "$$ \\displaystyle\\log\\mathcal{L}(\\alpha,\\beta\\ |\\ w)\\ = \\sum_{w}  \\log \\big( 1 + \\alpha\\ w + \\beta\\ (1-w) \\big) - (\\alpha\\ S + \\beta\\ B) $$\n",
    "\n",
    "where  $\\alpha$ and $\\beta$ are the excess signal, and background fractions, and $S$ and $B$ are\n",
    "the expected numbers of signal and background counts for the cell, determined from the full data set and relative exposure for the cell.\n",
    "\n",
    "Usually, we assume $\\beta=0$, that the background is not varying, and look for signal variation.\n",
    "\n",
    "In the special case where all $w$ values are 1, this reduces to Poisson likelihood, with solution $\\alpha = (1-n/S)$,\n",
    "where $n$ is the the number of photons.\n",
    "\n",
    "This module uses this functional evaluation of the likelihood for a cell to define the poisson-like\n",
    "3-parameter function to approximate this likelihood.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import os, sys, pickle\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from scipy import (optimize, linalg)\n",
    "from scipy.linalg import (LinAlgError, LinAlgWarning)\n",
    "\n",
    "from utilities import  keyword_options\n",
    "from light_curves.poisson import *\n",
    "poisson_tolerance = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LogLike(object):\n",
    "    \"\"\" implement Kerr Eqn 2 for a single interval, or cell\n",
    "\n",
    "     - cell -- a dict with  w, S, B <br>\n",
    "            w may be an array of np.uint8: if so, divide by 256\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cell):\n",
    "        \"\"\" \n",
    "        \"\"\"\n",
    "        self.__dict__.update(cell)\n",
    "        assert self.n>0, f'No data for cell {cell}'\n",
    "        if type(self.w[0])==np.uint8:\n",
    "            self.w = np.array(self.w, np.float)/256\n",
    "\n",
    "\n",
    "\n",
    "    def fit_info(self, fix_beta=True):\n",
    "        \"\"\"Perform fits, return a dict with cell info\"\"\"\n",
    "        pars = self.solve(fix_beta)\n",
    "        if pars is None:\n",
    "            if self.verbose>0:\n",
    "                print(f'Fail fit for {self}')\n",
    "            #return None\n",
    "            raise RuntimeError(f'Fit failure: {self}')\n",
    "        hess = self.hessian(pars)\n",
    "        outdict = dict( counts=len(self.w) )\n",
    "        if len(pars)==1:\n",
    "            outdict.update(flux=round(pars[0],4), \n",
    "                           sig_flux=round(np.sqrt(1/hess[0]),4) )\n",
    "        else:\n",
    "            beta = pars[1]\n",
    "            var  = np.linalg.inv(hess)\n",
    "            err  = np.sqrt(var.diagonal())\n",
    "            sig_flux=err[0]\n",
    "            sig_beta=err[1]\n",
    "            corr = var[0,1]/(err[0]*err[1])\n",
    "            outdict.update(flux=pars[0], beta=beta,\n",
    "                        sig_flux=sig_flux, sig_beta=sig_beta,corr=corr)\n",
    "        return outdict\n",
    "\n",
    "    def __call__(self, pars ):\n",
    "        \"\"\" evaluate the log likelihood\n",
    "            pars: array or float\n",
    "                if array with len>1, expect (rate, beta)\n",
    "        \"\"\"\n",
    "        pars = np.atleast_1d(pars)\n",
    "        if len(pars)>1:      alpha, beta = pars - np.array([-1,0])\n",
    "        else:                alpha, beta = max(-1, pars[0]-1), 0\n",
    "\n",
    "        tmp =  1 + alpha*self.w + beta*(1-self.w)\n",
    "        # limit alpha\n",
    "        tmp[tmp<=1e-6]=1e-6\n",
    "\n",
    "        return np.sum( np.log(tmp)) - alpha*self.S - beta*self.B\n",
    "\n",
    "    def __repr__(self):\n",
    "        time = f' time {self.t:.3f},' if hasattr(self, 't') else ''\n",
    "        return f'{self.__class__.__module__}.{self.__class__.__name__}:'\\\n",
    "        f' {time} {self.n} weights, S {self.S:.1f}, B {self.B:.1f}'\n",
    "\n",
    "    def gradient(self, pars ):\n",
    "        \"\"\"gradient of the log likelihood with respect to alpha=flux-1 and beta, or just alpha\n",
    "        \"\"\"\n",
    "        w,S = self.w, self.S\n",
    "        pars = np.atleast_1d(pars)\n",
    "\n",
    "        alpha =  max(-0.999,pars[0] -1)\n",
    "        if len(pars)==1:\n",
    "            D = 1 + alpha*w\n",
    "            return np.sum(w/D) - S\n",
    "        else:\n",
    "            beta = pars[1]\n",
    "            D =  1 + alpha*w + beta*(1-w)\n",
    "            da = np.sum(w/D) - S\n",
    "            db = np.sum((1-w)/D) - self.B\n",
    "            return [da,db]\n",
    "\n",
    "    def hessian(self, pars):\n",
    "        \"\"\"return Hessian matrix (1 or 2 D according to pars) from explicit second derivatives\n",
    "        Note this is also the Jacobian of the gradient.\n",
    "        \"\"\"\n",
    "        w = self.w\n",
    "        pars = np.atleast_1d(pars)\n",
    "        alpha = max(-0.999, pars[0]-1)\n",
    "        if  len(pars)==1:\n",
    "            D = 1 + alpha*w\n",
    "            return [np.sum((w/D)**2)]\n",
    "        else:\n",
    "            beta= pars[1]\n",
    "            Dsq = (1 + alpha*w + beta*(1-w))**2\n",
    "            a, b, c = np.sum(w**2/Dsq), np.sum(w*(1-w)/Dsq), np.sum((1-w)**2/Dsq)\n",
    "            return np.array([[a,b], [b,c]])\n",
    "\n",
    "    def rate(self, fix_beta=True, debug=False, no_ts=False):\n",
    "        \"\"\"Return signal rate and its error\"\"\"\n",
    "        try:\n",
    "            s = self.solve(fix_beta )\n",
    "            if s is None:\n",
    "                return None\n",
    "            h = self.hessian(s)\n",
    "\n",
    "            v = 1./h[0] if fix_beta else linalg.inv(h)[0,0]\n",
    "            ts = None if no_ts else (0 if s[0]<=-1 else\n",
    "                 2*(self(s)-self( -1 if fix_beta else [-1,s[1]] )))\n",
    "            return (s[0]), np.sqrt(v), ts\n",
    "\n",
    "        except (LinAlgError, LinAlgWarning, RuntimeWarning) as msg:\n",
    "            if debug or self.verbose>2:\n",
    "                print(f'Fit error, cell {self},\\n\\t{msg}')\n",
    "        except Exception as msg:\n",
    "            print(f'exception: {msg}')\n",
    "            raise\n",
    "        print( '***********Failed?')\n",
    "\n",
    "    def minimize(self,   fix_beta=True,estimate=[0.,0], **fmin_kw):\n",
    "        \"\"\"Minimize the -Log likelihood \"\"\"\n",
    "        kw = dict(disp=False)\n",
    "        kw.update(**fmin_kw)\n",
    "        f = lambda pars: -self(pars)\n",
    "        return optimize.fmin_cg(f, estimate[0:1] if fix_beta else estimate, **kw)\n",
    "\n",
    "    def solve(self, fix_beta=True, debug=True, estimate=[0.1,0],**fit_kw):\n",
    "        \"\"\"Solve non-linear equation(s) from setting gradient to zero\n",
    "        note that the hessian is a jacobian\n",
    "        \"\"\"\n",
    "\n",
    "        if fix_beta:\n",
    "            #\n",
    "            g0= self.gradient([0])\n",
    "            # solution is at zero flux\n",
    "            if g0<=0:\n",
    "                return [0]\n",
    "            # check that solution close to zero, difficult for fsolve.\n",
    "            # if < 0.5 sigma away, just give linear solution\n",
    "            h0=self.hessian(0)[0]\n",
    "            if g0/h0 < 0.5*np.sqrt(1/h0):\n",
    "                return [g0/h0]\n",
    "\n",
    "        kw = dict(factor=2, xtol=1e-3, fprime=self.hessian)\n",
    "        kw.update(**fit_kw)\n",
    "        try:\n",
    "            ret = optimize.fsolve(self.gradient, estimate[0] if fix_beta else estimate , **kw)\n",
    "        except RuntimeWarning as msg:\n",
    "            if debug or self.verbose>2:\n",
    "                print(f'Runtime fsolve warning for cell {self}, \\n\\t {msg}')\n",
    "            return None\n",
    "        except Exception as msg:\n",
    "            raise Exception(msg)\n",
    "        return np.array(ret)\n",
    "\n",
    "    def plot(self, fix_beta=True, xlim=(0,1.2),ax=None, title=None):\n",
    "        fig, ax = plt.subplots(figsize=(4,2)) if ax is None else (ax.figure, ax)\n",
    "\n",
    "        dom = np.linspace(*xlim)\n",
    "        if fix_beta:\n",
    "            f = lambda x: self([x])\n",
    "            beta=0\n",
    "        else:\n",
    "            a, beta = self.solve(fix_beta, debug=True)\n",
    "            f = lambda x: self([x, beta])\n",
    "        ax.plot(dom, list(map(f,dom)) )\n",
    "\n",
    "        try:\n",
    "            a, s, ts = self.rate(fix_beta=fix_beta, debug=True)\n",
    "            ax.plot(a, f(a), 'or')\n",
    "            ax.plot([a-s, a+s], [f(a-s), f(a+s)], '-k',lw=2)\n",
    "            for x in (a-s,a+s):\n",
    "                ax.plot([x,x], [f(x)-0.1, f(x)+0.1], '-k',lw=2)\n",
    "            ax.plot(a, f(a)-0.5, '-ok', ms=10)\n",
    "            ax.set(title=title, xlim=xlim, ylim=(f(a)-4, f(a)+0.2),\n",
    "               ylabel='log likelihood', xlabel='flux')\n",
    "        except Exception as msg :\n",
    "            print(msg)\n",
    "            ax.set(title=' **failed fit**')\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"LogLike\" class=\"doc_header\"><code>class</code> <code>LogLike</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>LogLike</code>(**`cell`**)\n",
       "\n",
       "implement Kerr Eqn 2 for a single interval, or cell\n",
       "\n",
       "- cell -- a dict with  w, S, B <br>\n",
       "       w may be an array of np.uint8: if so, divide by 256"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "show_doc(LogLike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Create a cell for further tests. Plot the likelihood for a cell with 100 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__.LogLike:  100 weights, S 80.0, B 20.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a cell with 100 weights equal to 0.8\n",
    "n = 100\n",
    "w = np.full(n, 0.8, np.float32)\n",
    "cell = dict( n=n, w=w, S=80, B=20 )\n",
    "\n",
    "ll = LogLike(cell)\n",
    "print(ll)\n",
    "ll.plot(xlim=(0.5,1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GaussianRep(object):\n",
    "    \"\"\" Manage fits to the loglike object\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike, fix_beta=True):\n",
    "        \"\"\"1- or 2-D fits to LogLike\"\"\"\n",
    "        self.fix_beta = fix_beta\n",
    "        self.fit = loglike.fit_info(fix_beta)\n",
    "\n",
    "    def __call__(self, pars):\n",
    "        return None # TODO if needed\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__module__}.{self.__class__.__name__}:\\n{pd.Series(self.fit)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 1-D gaussian fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.GaussianRep:\n",
       "counts      100.000\n",
       "flux          1.000\n",
       "sig_flux      0.125\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = GaussianRep(ll); gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Gaussian2dRep(GaussianRep):\n",
    "    def __init__(self, loglike):\n",
    "        super(Gaussian2dRep, self).__init__(loglike, fix_beta=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the rate is significant, more than 5 $\\sigma$, the resulting poisson-like parameters are\n",
    "straight-forward to fit.  \n",
    "\n",
    "If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,\n",
    "so $s > 5\\sqrt{v} $, then we determine the poisson-like parameters as follows.\n",
    "\n",
    "We use the properties of the Poisson distribution \n",
    "$f(n;\\lambda) = \\exp(n \\log\\lambda - \\lambda + \\mathrm{const})$, \n",
    "where the parameter $\\lambda$ is equal to the expected value of number of occurrences $n$ and \n",
    "to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor\n",
    "$k$ so we use $f(k(s-b); \\lambda)$ This implies that for the expected value of $s$, $\\lambda = n$,\n",
    "and $ k(s-b)= k^2 v = n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from which we obtain $k=\\sqrt{n}/v$ and $b=s-k/n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PoissonRep(object):\n",
    "    \"\"\"Manage the representation of the log likelihood of a cell by a `Poisson`.\n",
    "    \n",
    "    - loglike: a LogLike object\n",
    "    - thresh: threshold to assume no Bayesian restriction\n",
    "                   \n",
    "    Constructor takes a `LogLike` object, fits it to the poisson-like function (see `Poisson`), and \n",
    "    defines a function to evaluate that.\n",
    "    \n",
    "    Note that beta is set to zero.\n",
    "    \n",
    "    If the rate is significant, more than 5 $\\sigma$, so that the likelihood is not truncated by the\n",
    "    Bayesian requirement, the resulting poisson-like parameters are   straightforward to determine.  \n",
    "\n",
    "    If $s$ and $v$ are the signal rate and its  variance, determined by the 1-d Gaussian fit for $n$ measurements,\n",
    "    so $s > 5\\sqrt{v} $, then we determine the poisson-like parameters as follows.\n",
    "\n",
    "    We use the properties of the Poisson distribution \n",
    "    $f(n;\\lambda) = \\exp(n \\log\\lambda - \\lambda + \\mathrm{const})$, \n",
    "    where the parameter $\\lambda$ is equal to the expected value of number of occurrences $n$ and \n",
    "    to its variance, and that the function we want is shifted by the background $b$ and scaled by a factor\n",
    "    $k$ so we use $f(k(s-b); \\lambda)$ This implies that for the expected value of $s$, $\\lambda = n$,\n",
    "    and $ k(s-b)= k^2 v = n$.\n",
    "    \n",
    "\n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike, tol=poisson_tolerance,  # note global\n",
    "                 thresh = 5, \n",
    "                ):\n",
    "        \"\"\"\n",
    " \n",
    "        \"\"\"\n",
    "        \n",
    "        self.loglike = loglike # do I need this? lots of memory for the array of weights\n",
    "        rate, sig, self.ts= loglike.rate()\n",
    " \n",
    "\n",
    "        # note that variance v = (rate*sig)**2\n",
    "        if sig< 1/thresh: # can use the simple non-truncated Poisson distribution.\n",
    "            n = loglike.n\n",
    "            mu, beta = n, n-np.sqrt(n)/sig \n",
    "            k = rate * (mu-beta)\n",
    "            b = beta/k\n",
    "            self.poiss = Poisson((rate, k, b))\n",
    "            self.pf = None \n",
    "        \n",
    "        else:\n",
    "            # fit bring in the fitter\n",
    "       \n",
    "            fmax=max(0, rate)\n",
    "            ## NB: the dd=-10 is a kluge for very small limits, set for loglike stuff with different scales.\n",
    "            # this seems to work, but must be looked at more carefully\n",
    "            try:\n",
    "                self.pf = PoissonFitter(loglike, fmax=fmax, scale=sig if rate>0 else 1,  dd=-10., tol=tol)\n",
    "            except Exception as msg:\n",
    "                print(f'Fail poisson fit for {loglike}: {msg}')\n",
    "                with open('failed_loglike.pkl', 'wb') as file:\n",
    "                    pickle.dump(loglike, file)\n",
    "                print('Saved file')\n",
    "                raise\n",
    "\n",
    "            self.poiss=self.pf.poiss\n",
    "            \n",
    "        p = self\n",
    "        # pass on t, tw, e if there else enter 0,1,1\n",
    "        self.fit= dict(t= loglike.t if hasattr(loglike, 't') else 0, \n",
    "                       tw=loglike.tw if hasattr(loglike, 'tw') else 1, \n",
    "                       counts=len(loglike.w),\n",
    "                       e=loglike.e if hasattr(loglike, 'e') else 1,\n",
    "                       flux=np.round(p.flux,4),\n",
    "                       errors=np.abs(np.array(p.errors)-p.flux).round(3),\n",
    "                       limit=np.round(p.limit, 3),\n",
    "                       ts=np.round(p.ts,3),\n",
    "                       poiss_pars=list(np.float32(self.poiss.p)),\n",
    "                      )\n",
    "\n",
    "    def __call__(self, flux):\n",
    "        return self.poiss(flux)\n",
    "\n",
    "    def __repr__(self):\n",
    "        relerr = np.abs(np.array(self.errors)/self.flux-1) if self.flux>0 else [0,0]\n",
    "        return  f'  {self.flux:.3f}[1+{relerr[0]:.3f}-{relerr[1]:.3f}], '\\\n",
    "                f'< {self.limit:.2f}'\n",
    "    @property\n",
    "    def flux(self):\n",
    "        return self.poiss.flux\n",
    "    @property\n",
    "    def errors(self):\n",
    "        return self.poiss.errors\n",
    "    @property\n",
    "    def limit(self):\n",
    "        \"\"\" 95% confidence interval\"\"\"\n",
    "        return self.poiss.cdfcinv(0.05)\n",
    "    \n",
    "    def cl(self, x):\n",
    "        \"\"\"Confidence level\"\"\"\n",
    "        return self.poiss.cdfc(x)\n",
    "\n",
    "    def create_table(self, npts=100, support=1e-6):\n",
    "        # make a table of evently-spaced points between limits\n",
    "        pars = self.fit['poiss_pars']\n",
    "        p = Poisson(pars)\n",
    "        a,b = p.cdfinv(support), p.cdfcinv(support)\n",
    "        dom=(a,b,npts)\n",
    "        cod = np.array(list(map(p, np.linspace(*dom)))) .astype(np.float32)\n",
    "        return dom, cod\n",
    "\n",
    "    def comparison_plots(self, xlim=(0,1), ax=None, nbins=40):\n",
    "        \"\"\"Plots comparing this approximation to the actual likelihhod\n",
    "        \"\"\"\n",
    "        f_like = lambda x: self(x)\n",
    "        #pr = light_curve.PoissonRep(self);\n",
    "        fp = lambda x: self(x)\n",
    "        f_like = lambda x: self.loglike([x])\n",
    "        fi = self.loglike.fit_info()\n",
    "        xp = fi['flux']\n",
    "        sigp = fi['sig_flux']\n",
    "        peak = f_like(xp)\n",
    "        dom = np.linspace(xlim[0],xlim[1],nbins)\n",
    "        f_gauss = lambda x: -((x-xp)/sigp)**2/2\n",
    "        fig, ax = plt.subplots(figsize=(6,4)) if not ax else (ax.figure, ax)\n",
    "        ax.plot(dom, [f_like(x)-peak for x in dom], '-', label='Actual Likelihood');\n",
    "        ax.plot(dom, fp(dom), '--+', lw=1, label='Poisson approximation');\n",
    "        ax.plot(dom, [f_gauss(x) for x in dom], ':r', label='Gaussian approximation');\n",
    "        ax.grid(alpha=0.5);\n",
    "        ax.set(ylim=(-9,0.5));\n",
    "        ax.axhline(0, color='grey', ls='--')\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson representation development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLike fit info:{'counts': 100, 'flux': 1.0, 'sig_flux': 0.125}\n",
      "PoissonRep:   1.000[1+0.121-0.129], < 1.23, poiss: Poisson: mu,beta= 100.0, 20.0\n",
      "poisson pars: [ 1.   80.    0.25]\n",
      "Get poisson parmeters from n=100, m=1.0, sig=0.125\n",
      "Poisson: mu,beta= 100.0, 20.0 [1.0, 80.0, 0.25]\n"
     ]
    }
   ],
   "source": [
    "info = ll.fit_info()\n",
    "print(f'LogLike fit info:{info}')\n",
    "pr = PoissonRep(ll, thresh=5)\n",
    "print(f'PoissonRep: {pr}, poiss: {pr.poiss}')\n",
    "pars = np.array(pr.poiss.p).round(3)\n",
    "print(f'poisson pars: {pars}')\n",
    "\n",
    "\n",
    "n, m, sig = np.array(list(info.values())).round(3)\n",
    "print(f'Get poisson parmeters from n={int(n)}, m={m}, sig={sig}')\n",
    "mu, beta = n, n-np.sqrt(n)/sig\n",
    "e = m*(mu-beta)\n",
    "b = beta/e\n",
    "pois = Poisson([m, e , b])\n",
    "print(pois, pois.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PoissonRepTable(PoissonRep):\n",
    "    \"\"\"\n",
    "    Create a table, then interpolate it\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loglike):\n",
    "        # PoissonRep fits to Poisson\n",
    "        super().__init__(loglike, )\n",
    "        # now make a table and add to dict\n",
    "        self.dom,self.cod = self.create_table()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return np.interp(x, np.linspace(*self.dom), self.cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5025044369392521, 1.7019376590709014, 100)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prt = PoissonRepTable(ll)\n",
    "prt.dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 06_poisson.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_loglike.ipynb.\n",
      "Converted 09_lightcurve.ipynb.\n",
      "Converted 10_simulation.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted 90_analysis.ipynb.\n",
      "Converted index.ipynb.\n",
      "Fri Dec 25 07:25:02 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
