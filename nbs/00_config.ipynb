{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#default_exp config\n",
    "%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "\n",
    "def MJD(met):\n",
    "    \"convert MET to MJD\"\n",
    "    #mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "    # From a FT2 file header\n",
    "    # MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "    # MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "    mission_start = 51910.00074287037\n",
    "    return (mission_start + met/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration data classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Default light curve configuration parameters\"\"\"\n",
    "    verbose : int = 3\n",
    "    use_cache : bool = True\n",
    "\n",
    "    # photon selection\n",
    "    mjd_range : Tuple=None\n",
    "    radius: float = 5\n",
    "    cos_theta_max:float=0.4\n",
    "    z_max : float=100\n",
    "\n",
    "    # binning\n",
    "    energy_edges = np.logspace(2,6,17)\n",
    "    time_interval: int = 1\n",
    "\n",
    "    # healpix data representation used by data\n",
    "    nside : int=1024\n",
    "    nest: bool=True\n",
    "\n",
    "    # exposure calculation\n",
    "    bins_per_decade: int=4\n",
    "    base_spectrum: str='lambda E: (E/1000)**-2.1'\n",
    "    energy_range: Tuple = (100.,1e6)\n",
    "        \n",
    "    # analysis\n",
    "    likelihood_rep: str='poisson'\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "    \n",
    "    def __repr__(self): return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration parameters \n",
       "  verbose         : 3\n",
       "  use_cache       : True\n",
       "  mjd_range       : None\n",
       "  radius          : 5\n",
       "  cos_theta_max   : 0.4\n",
       "  z_max           : 100\n",
       "  time_interval   : 1\n",
       "  nside           : 1024\n",
       "  nest            : True\n",
       "  bins_per_decade : 4\n",
       "  base_spectrum   : lambda E: (E/1000)**-2.1\n",
       "  energy_range    : (100.0, 1000000.0)\n",
       "  likelihood_rep  : poisson"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "class _Cache(dict):\n",
    "    \n",
    "    def __init__(self, path, clear=False):\n",
    "        self.path = Path(path)\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():  \n",
    "            if clear: \n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "        else:\n",
    "            self.path.mkdir()        \n",
    "        self.index = len(list(self.path.iterdir()))\n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        \n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists(): \n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "        \n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for {key} exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[2:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index() \n",
    " \n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "    \n",
    "    def clear(self):\n",
    "        \n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file: \n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "        \n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        filename.unlink()\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "        \n",
    "            \n",
    "                \n",
    "    def __call__(self, key, \n",
    "                 func:'user function',\n",
    "                 overwrite:'set to overwrite if exists'=False, \n",
    "                 *pars, **kwargs\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usagge\n",
    "        \n",
    "        cache = _Cache(path)\n",
    "        result = cache(key, function, *pars, **kwargs)\n",
    "        \"\"\"\n",
    "        ret = self.get(key)\n",
    "        if ret is None or overwrite: \n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "{'one': Path('/tmp/test_cache/cache_file_x7d12ee9d3b7cf548.pkl'), 'two': Path('/tmp/test_cache/cache_file_x701df7dd200ae1f.pkl'), 'three': Path('/tmp/test_cache/cache_file_x1eb9e18e1559b080.pkl'), 'four': Path('/tmp/test_cache/cache_file_x57b2e4450c14754d.pkl')}\n",
      "{'one': Path('/tmp/test_cache/cache_file_x7d12ee9d3b7cf548.pkl'), 'two': Path('/tmp/test_cache/cache_file_x701df7dd200ae1f.pkl'), 'three': Path('/tmp/test_cache/cache_file_x1eb9e18e1559b080.pkl')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for two exists\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "c = _Cache('/tmp/test_cache', clear=True)\n",
    "\n",
    "c.add('one', 'one');\n",
    "c.add('two', 'two')\n",
    "c.add('two', 'two')\n",
    "\n",
    "ret = c.get('three') \n",
    "if ret is None:\n",
    "    ret = 'three'\n",
    "    c.add('three', ret)\n",
    "r1 = c('four', lambda x:f'value: {x}', 4)\n",
    "r2 = c('four', lambda x:f'value: {x}', 5) #should not get called\n",
    "assert r1==r2\n",
    "print(c)\n",
    "c.remove('four')\n",
    "assert 'four' not in c\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Files:\n",
    "    \"\"\" paths to the various files that we need\"\"\"\n",
    "\n",
    "    data:str = '$HOME/data'\n",
    "    ft2: str = '$HOME/work/lat-data/ft2'\n",
    "    gti: str = '$HOME/work/lat-data/binned/'\n",
    "    aeff:str = '$HOME/work/lat-data/aeff'\n",
    "    weights: str = '$HOME/onedrive/fermi/weight_files'\n",
    "    cachepath: str = '/tmp/lc_cache'\n",
    "\n",
    "    # expand -- not implemented in Path\n",
    "    def __post_init__(self):\n",
    "        d = self.__dict__\n",
    "        for name, value in d.items():\n",
    "            d[name] = Path(os.path.expandvars(value))\n",
    "        self.cachepath.mkdir(exist_ok=True)\n",
    "        self.cache = _Cache(self.cachepath, clear=False)\n",
    "        \n",
    "    @property\n",
    "    def valid(self):\n",
    "        \"\"\"assume all files ok if aeff\"\"\"\n",
    "        return self.aeff.exists()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'File paths for light curves\\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            s += f'  {name:10s} : {value}\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File paths for light curves\n",
       "  data       : /home/burnett/data\n",
       "  ft2        : /home/burnett/work/lat-data/ft2\n",
       "  gti        : /home/burnett/work/lat-data/binned\n",
       "  aeff       : /home/burnett/work/lat-data/aeff\n",
       "  weights    : /home/burnett/onedrive/fermi/weight_files\n",
       "  cachepath  : /tmp/lc_cache\n",
       "  cache      : {}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = Files()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "class PointSource():\n",
    "    \"\"\"Manage the position and name of a point source\n",
    "    \"\"\"\n",
    "    def __init__(self, name, position=None):\n",
    "        \"\"\"position: (l,b) tuple or None. if None, expect to be found by lookup\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        if position is None:\n",
    "            skycoord = SkyCoord.from_name(name)\n",
    "            gal = skycoord.galactic\n",
    "            self.l,self.b = (gal.l.value, gal.b.value)\n",
    "        else:\n",
    "            self.l,self.b = position\n",
    "            skycoord = SkyCoord(self.l,self.b, unit='deg', frame='galactic')\n",
    "        self.skycoord = skycoord\n",
    "    def __str__(self):\n",
    "        return f'Source \"{self.name}\" at: (l,b)=({self.l:.3f},{self.b:.3f})'\n",
    "    def __repr__(self): return str(self)\n",
    "\n",
    "    @property\n",
    "    def ra(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.ra.value\n",
    "    @property\n",
    "    def dec(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.dec.value\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        \"\"\"Modified name for file system\"\"\"\n",
    "        return self.name.replace(' ', '_').replace('+','p')\n",
    "\n",
    "    @classmethod\n",
    "    def fk5(cls, name, position):\n",
    "        \"\"\"position: (ra,dec) tuple \"\"\"\n",
    "        ra,dec = position\n",
    "        sk = SkyCoord(ra, dec, unit='deg',  frame='fk5').transform_to('galactic')\n",
    "        return cls(name, (sk.l.value, sk.b.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"PointSource.fk5\" class=\"doc_header\"><code>PointSource.fk5</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PointSource.fk5</code>(**`name`**, **`position`**)\n",
       "\n",
       "position: (ra,dec) tuple "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PointSource.fk5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, expect in [( PointSource('Geminga'),             'Source \"Geminga\" at: (l,b)=(195.134,4.266)'),\n",
    "                  ( PointSource('gal_source', (0,0)),   'Source \"gal_source\" at: (l,b)=(0.000,0.000)', ),\n",
    "                  ( PointSource.fk5('fk5_source',(0,0)),'Source \"fk5_source\" at: (l,b)=(96.337,-60.189)',)\n",
    "                   ]:    \n",
    "    assert str(s)==expect, f'expected {expect}, got {str(s)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = Files()\n",
    "files.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_load_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 09_poisson.ipynb.\n",
      "Converted 10_loglike.ipynb.\n",
      "Converted 11_lightcurve.ipynb.\n",
      "Converted 12_instructions.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n",
      "Mon Dec 14 10:46:22 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
