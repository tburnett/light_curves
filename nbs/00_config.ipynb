{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp config\n",
    "%load_ext autoreload\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration data and basic functions\n",
    "> Basic functions and configuration stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time conversion\n",
    "\n",
    "- MET: mission elapsed time\n",
    "- MJD: modified Julian date (days)\n",
    "- UTC: ISO time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "day = 24*3600.\n",
    "first_data=54683\n",
    "\n",
    "def MJD(met):\n",
    "    \"convert MET to MJD\"\n",
    "    #mission_start = Time('2001-01-01T00:00:00', scale='utc').mjd\n",
    "    # From a FT2 file header\n",
    "    # MJDREFI =               51910. / Integer part of MJD corresponding to SC clock S\n",
    "    # MJDREFF =  0.00074287037037037 / Fractional part of MJD corresponding to SC cloc\n",
    "    mission_start = 51910.00074287037\n",
    "    return (mission_start + met/day  )\n",
    "\n",
    "def UTC(mjd):\n",
    "    \" convert MJD value to ISO date string\"\n",
    "    t=Time(mjd, format='mjd')\n",
    "    t.format='iso'; t.out_subfmt='date_hm'\n",
    "    return t.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert UTC(MJD(0))=='2001-01-01 00:01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "\n",
    "class Cache(dict):\n",
    "    \"\"\"\n",
    "    Manage a file cache\n",
    "\n",
    "    - `path` -- string or `filepath` object\n",
    "    - `clear` -- set True to clear the cache\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, clear:bool=False):\n",
    "\n",
    "\n",
    "        self.path = Path(path) if path else None\n",
    "        if not self.path: return\n",
    "        self.path.mkdir(exist_ok=True)\n",
    "        assert self.path.exists()\n",
    "        self.index_file = self.path/'index.pkl'\n",
    "\n",
    "        if self.path.exists():  \n",
    "            if clear: \n",
    "                print('Clearing cache!')\n",
    "                self.clear()\n",
    "            else:\n",
    "                self._load_index()\n",
    "        else:\n",
    "            self.path.mkdir(exist_ok=True)        \n",
    "\n",
    "    def _dump_index(self):\n",
    "        with open(self.index_file, 'wb') as file:\n",
    "            pickle.dump(self, file)\n",
    "        \n",
    "    def _load_index(self):\n",
    "        if not self.index_file.exists(): \n",
    "            self._dump_index()\n",
    "            return\n",
    "        with open(self.index_file, 'rb') as file:\n",
    "            self.update(pickle.load(file))\n",
    "        \n",
    "    def add(self, key, object, exist_ok=False):\n",
    "        if not self.path: return\n",
    "        if key  in self:\n",
    "            if not exist_ok:\n",
    "                print(f'Warning: cached object for key \"{key}\" exists', file=sys.stderr)\n",
    "            filename = self[key]\n",
    "        else:\n",
    "            filename = self.path/f'cache_file_{hex(key.__hash__())[3:]}.pkl'\n",
    "            self[key] = filename\n",
    "            self._dump_index() \n",
    " \n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(object, file )\n",
    "\n",
    "        \n",
    "    def get(self, key):\n",
    "        if key not in self:\n",
    "            return None\n",
    "        filename = self[key]\n",
    "        with open(filename, 'rb') as file:\n",
    "            ret = pickle.load(file)\n",
    "        return ret\n",
    "    \n",
    "    def clear(self):\n",
    "        if not self.path: return\n",
    "        for f in self.path.iterdir():\n",
    "            if f.is_file: \n",
    "                f.unlink()\n",
    "        super().clear()\n",
    "\n",
    "        self._dump_index()\n",
    "        \n",
    "    def remove(self, key):\n",
    "        \"\"\"remove entry and associated file\"\"\"\n",
    "        if not self.path: return\n",
    "        if key not in self:\n",
    "            print(f'Cache: key {key} not found', file=sys.stderr)\n",
    "            return\n",
    "        filename = self[key]\n",
    "        filename.unlink()\n",
    "        super().pop(key)\n",
    "        self._dump_index()\n",
    "        \n",
    "                \n",
    "    def __call__(self, key, func, *pars, description='', overwrite=False, **kwargs,\n",
    "                ):\n",
    "        \"\"\"\n",
    "        One-line usage interface for cache use\n",
    "        \n",
    "        - `key` -- key to use, usually a string. Must be hashable <br>\n",
    "            If none, ignore cache and return the function evaluation\n",
    "        - `func` -- user function that will return an object that can be pickled\n",
    "        - `pars`, `kwargs` -- pass to `func`\n",
    "        - `description` -- optional string that will be printed\n",
    "\n",
    "        \n",
    "        cache = Cache(path)\n",
    "        result = cache(key, function, *pars, **kwargs)\n",
    "        \"\"\"\n",
    "        \n",
    "        if key is None:\n",
    "            return func(*pars, **kwargs)\n",
    "        \n",
    "        ret = self.get(key)\n",
    "        if description:\n",
    "            print(f'{description}: {\"Saving to\" if key not in self else \"Restoring from\"} cache with key \"{key}\"')\n",
    "\n",
    "        if ret is None or overwrite: \n",
    "            ret = func(*pars, **kwargs)\n",
    "            self.add(key, ret)\n",
    "        return ret\n",
    "             \n",
    "    def __str__(self):\n",
    "        import datetime\n",
    "        if not self.path: return 'Cache not enabled'\n",
    "        s = f'Cache contents\\n {\"key\":20}   {\"size\":>10}  {\"time\":20} {\"name\"}, in folder {self.path}\\n'\n",
    "        for name, value in self.items():\n",
    "            if name is None: continue\n",
    "            stat = value.stat()\n",
    "            size = stat.st_size\n",
    "            mtime= str(datetime.datetime.fromtimestamp(stat.st_mtime))[:16]\n",
    "            s += f'  {name:20s}  {size:10}  {mtime:20} {value.name}\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"Cache\" class=\"doc_header\"><code>class</code> <code>Cache</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>Cache</code>(**`path`**, **`clear`**:`bool`=*`False`*) :: `dict`\n",
       "\n",
       "Manage a file cache\n",
       "\n",
       "- `path` -- string or `filepath` object\n",
       "- `clear` -- set True to clear the cache"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cache.__call__\" class=\"doc_header\"><code>Cache.__call__</code><a href=\"__main__.py#L86\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cache.__call__</code>(**`key`**, **`func`**, **\\*`pars`**, **`description`**=*`''`*, **`overwrite`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "One-line usage interface for cache use\n",
       "\n",
       "- `key` -- key to use, usually a string. Must be hashable <br>\n",
       "    If none, ignore cache and return the function evaluation\n",
       "- `func` -- user function that will return an object that can be pickled\n",
       "- `pars`, `kwargs` -- pass to `func`\n",
       "- `description` -- optional string that will be printed\n",
       "\n",
       "\n",
       "cache = Cache(path)\n",
       "result = cache(key, function, *pars, **kwargs)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing cache!\n",
      "Test: Saving to cache with key \"four\"\n",
      "Test: Restoring from cache with key \"four\"\n",
      "Before remove:\n",
      "Cache contents\n",
      " key                          size  time                 name, in folder /tmp/test_cache\n",
      "  one                           13  2020-12-18 10:08     cache_file_ff9a98a1b6f7456.pkl\n",
      "  two                           13  2020-12-18 10:08     cache_file_a24b9e6f3e5af9c.pkl\n",
      "  four                          18  2020-12-18 10:08     cache_file_3a7ac979522ff17a.pkl\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: cached object for key \"two\" exists\n"
     ]
    }
   ],
   "source": [
    "#collapse_hide\n",
    "show_doc(Cache)\n",
    "show_doc(Cache.__call__)\n",
    "def cache_test(path):\n",
    "    c = Cache(path, clear=True)\n",
    "\n",
    "    # simmple interface\n",
    "    c.add('one', 'one');\n",
    "    c.add('two', 'two')\n",
    "    c.add('two', 'two') # getnerates warning\n",
    "    if path is not None:\n",
    "        assert c.get('two') == 'two'\n",
    "\n",
    "    # test function interface\n",
    "    func = lambda x:f'value: {x}'\n",
    "    \n",
    "    r1 = c('four',  func,  4, description='Test')\n",
    "    r2 = c('four',  func,  5,  description='Test') #should not get called\n",
    "    assert c.path is None or r1==r2, f'{r1}, {r2}'\n",
    "    \n",
    "    # remaving an entry\n",
    "    print(f'Before remove:\\n{c}')\n",
    "    assert 'four' in c\n",
    "    c.remove('four')\n",
    "    assert 'four' not in c\n",
    "   \n",
    "    \n",
    "    c.clear()\n",
    "cache_test('/tmp/test_cache')\n",
    "# disabled should ignore\n",
    "#cache_test(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration data classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Files:\n",
    "    \"\"\" paths to the various files that we need\"\"\"\n",
    "\n",
    "    data:str = '$HOME/data'\n",
    "    ft2: str = '$HOME/work/lat-data/ft2'\n",
    "    gti: str = '$HOME/work/lat-data/binned/'\n",
    "    aeff:str = '$HOME/work/lat-data/aeff'\n",
    "    weights: str = '$HOME/onedrive/fermi/weight_files'\n",
    "    cachepath: str = '/tmp/lc_cache'\n",
    "\n",
    "    # expand -- not implemented in Path\n",
    "    def __post_init__(self):\n",
    "        d = self.__dict__\n",
    "        for name, value in d.items():\n",
    "            d[name] = Path(os.path.expandvars(value))\n",
    "#         self.cachepath.mkdir(exist_ok=True)\n",
    "#         self.cache = Cache(self.cachepath, clear=False)\n",
    "        \n",
    "    @property\n",
    "    def valid(self):\n",
    "        \"\"\"assume all files ok if aeff\"\"\"\n",
    "        return self.aeff.exists()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = 'File paths for light curves\\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            s += f'  {name:10s} : {value}\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File paths for light curves\n",
       "  data       : /home/burnett/data\n",
       "  ft2        : /home/burnett/work/lat-data/ft2\n",
       "  gti        : /home/burnett/work/lat-data/binned\n",
       "  aeff       : /home/burnett/work/lat-data/aeff\n",
       "  weights    : /home/burnett/onedrive/fermi/weight_files\n",
       "  cachepath  : /tmp/lc_cache"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Default light curve configuration parameters\"\"\"\n",
    "    verbose : int = 3\n",
    "    files :'' =  None\n",
    "\n",
    "    # photon selection\n",
    "    mjd_range : Tuple=None\n",
    "    radius: float = 5\n",
    "    cos_theta_max:float=0.4\n",
    "    z_max : float=100\n",
    "\n",
    "    # binning\n",
    "    energy_edges = np.logspace(2,6,17)\n",
    "    time_interval: int = 1\n",
    "\n",
    "    # healpix data representation used by data\n",
    "    nside : int=1024\n",
    "    nest: bool=True\n",
    "\n",
    "    # exposure calculation\n",
    "    bins_per_decade: int=4\n",
    "    base_spectrum: str='lambda E: (E/1000)**-2.1'\n",
    "    energy_range: Tuple = (100.,1e6)\n",
    "        \n",
    "    # analysis\n",
    "    likelihood_rep: str='poisson'\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        if self.files is None: self.files=Files()\n",
    "        chpath = self.files.cachepath\n",
    "        chpath.mkdir(exist_ok=True)\n",
    "        self.cache = Cache(chpath, clear=False)\n",
    "        \n",
    " \n",
    "    @property\n",
    "    def valid(self):\n",
    "        return self.files.valid\n",
    "    \n",
    "    def __str__(self):\n",
    "        s = 'Configuration parameters \\n'\n",
    "        for name, value in self.__dict__.items():\n",
    "            if name=='files': continue\n",
    "            s += f'  {name:15s} : {value}\\n'\n",
    "        return s\n",
    "\n",
    "    def __repr__(self): return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache contents\n",
      " key                          size  time                 name, in folder /tmp/lc_cache\n",
      "  gti                      1018319  2020-12-17 15:17     cache_file_26e0b050cac876b4.pkl\n",
      "  exposure_Geminga        86263776  2020-12-17 15:47     cache_file_3d18a74e668c437.pkl\n",
      "  lightcurve_Geminga      12193571  2020-12-17 15:50     cache_file_5f8c1fe2233119ff.pkl\n",
      "  photons_3C 279           3659049  2020-12-17 15:50     cache_file_005a8b245230afe.pkl\n",
      "  exposure_3C 279         78040992  2020-12-17 15:51     cache_file_86f97125c87ecd8.pkl\n",
      "  lightcurve_3C 279        4687729  2020-12-17 15:51     cache_file_509522c898fe52.pkl\n",
      "  photons_Geminga         22334705  2020-12-18 06:39     cache_file_52b89da960a98f6.pkl\n",
      "  cells_Geminga            1500794  2020-12-18 08:48     cache_file_6f2eb7e7fa4947f8.pkl\n",
      "                           1500794  2020-12-18 08:51     cache_file_.pkl\n",
      "  lightfcurve_Geminga     12193634  2020-12-18 09:06     cache_file_f721860d03c0aa7.pkl\n",
      "  cells_3C 279              557725  2020-12-18 09:06     cache_file_3e45b0fd33e29f7.pkl\n",
      "  lightfcurve_3C 279       4687739  2020-12-18 09:06     cache_file_446256afd621452.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "print(config.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export                \n",
    "class PointSource():\n",
    "    \"\"\"Manage the position and name of a point source\n",
    "    \"\"\"\n",
    "    def __init__(self, name, position=None):\n",
    "        \"\"\"position: (l,b) tuple or None. if None, expect to be found by lookup\n",
    "        \"\"\"\n",
    "        self.name=name\n",
    "        if position is None:\n",
    "            skycoord = SkyCoord.from_name(name)\n",
    "            gal = skycoord.galactic\n",
    "            self.l,self.b = (gal.l.value, gal.b.value)\n",
    "        else:\n",
    "            self.l,self.b = position\n",
    "            skycoord = SkyCoord(self.l,self.b, unit='deg', frame='galactic')\n",
    "        self.skycoord = skycoord\n",
    "    def __str__(self):\n",
    "        return f'Source \"{self.name}\" at: (l,b)=({self.l:.3f},{self.b:.3f})'\n",
    "    def __repr__(self): return str(self)\n",
    "\n",
    "    @property\n",
    "    def ra(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.ra.value\n",
    "    @property\n",
    "    def dec(self):\n",
    "        sk = self.skycoord.transform_to('fk5')\n",
    "        return sk.dec.value\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        \"\"\"Modified name for file system\"\"\"\n",
    "        return self.name.replace(' ', '_').replace('+','p')\n",
    "\n",
    "    @classmethod\n",
    "    def fk5(cls, name, position):\n",
    "        \"\"\"position: (ra,dec) tuple \"\"\"\n",
    "        ra,dec = position\n",
    "        sk = SkyCoord(ra, dec, unit='deg',  frame='fk5').transform_to('galactic')\n",
    "        return cls(name, (sk.l.value, sk.b.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"PointSource.fk5\" class=\"doc_header\"><code>PointSource.fk5</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PointSource.fk5</code>(**`name`**, **`position`**)\n",
       "\n",
       "position: (ra,dec) tuple "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PointSource.fk5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, expect in [( PointSource('Geminga'),             'Source \"Geminga\" at: (l,b)=(195.134,4.266)'),\n",
    "                  ( PointSource('gal_source', (0,0)),   'Source \"gal_source\" at: (l,b)=(0.000,0.000)', ),\n",
    "                  ( PointSource.fk5('fk5_source',(0,0)),'Source \"fk5_source\" at: (l,b)=(96.337,-60.189)',)\n",
    "                   ]:    \n",
    "    assert str(s)==expect, f'expected {expect}, got {str(s)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_config.ipynb.\n",
      "Converted 01_effective_area.ipynb.\n",
      "Converted 02_load_gti.ipynb.\n",
      "Converted 03_exposure.ipynb.\n",
      "Converted 04_photon_data.ipynb.\n",
      "Converted 05_weights.ipynb.\n",
      "Converted 07_cells.ipynb.\n",
      "Converted 08_simulation.ipynb.\n",
      "Converted 09_poisson.ipynb.\n",
      "Converted 10_loglike.ipynb.\n",
      "Converted 11_lightcurve.ipynb.\n",
      "Converted 12_roadmap.ipynb.\n",
      "Converted 13_kerr_comparison.ipynb.\n",
      "Converted 14_bayesian.ipynb.\n",
      "Converted index.ipynb.\n",
      "Fri Dec 18 10:08:08 PST 2020\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
