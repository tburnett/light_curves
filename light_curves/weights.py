# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_weights.ipynb (unless otherwise specified).

__all__ = ['config', 'files', 'add_weights']

# Cell
import os,  pickle, healpy
import numpy as np
from .config import Config, Files, PointSource
from .load_gti import get_gti
from .photon_data import get_photon_data

config = None
files = None

# Cell
def _load_weights(filename, ):
    """Load the weight informaton

    filename: pickled dict with map info

    """
    # load a pickle containing weights, generated by pointlike
    assert os.path.exists(filename),f'File {filename} not found.'
    with open(filename, 'rb') as file:
        wtd = pickle.load(file, encoding='latin1')
    assert type(wtd)==dict, 'Expect a dictionary'
    test_elements = 'energy_bins pixels weights nside model_name radius order roi_name'.split()
    assert np.all([x in wtd.keys() for x in test_elements]),f'Dict missing one of the keys {test_elements}'
    if config.verbose>0:
        print(f'Load weights from file {os.path.realpath(filename)}')
        pos = wtd['source_lb']
        print(f'\tFound: {wtd["source_name"]} at ({pos[0]:.2f}, {pos[1]:.2f})')
    # extract pixel ids and nside used
    wt_pix   = wtd['pixels']
    nside_wt = wtd['nside']

    # merge the weights into a table, with default nans
    # indexing is band id rows by weight pixel columns
    # append one empty column for photons not in a weight pixel
    # calculated weights are in a dict with band id keys
    wts = np.full((32, len(wt_pix)+1), np.nan, dtype=np.float32)
    weight_dict = wtd['weights']
    for k in weight_dict.keys():
        t = weight_dict[k]
        if len(t.shape)==2:
            t = t.T[0] #???
        wts[k,:-1] = t
    return wts , wt_pix , nside_wt

# Cell
def _add_weights(wts, wt_pix, nside_wt, photon_data):
    # get the photon pixel ids, convert to NEST (if not already) and right shift them

    if not config.nest:
        # data are RING
        photon_pix = healpy.ring2nest(config.nside, photon_data.pixel.values)
    else:
        photon_pix = photon_data.pixel.values
    to_shift = 2*int(np.log2(config.nside/nside_wt));
    shifted_pix =   np.right_shift(photon_pix, to_shift)
    bad = np.logical_not(np.isin(shifted_pix, wt_pix))
    if config.verbose>0:
        print(f'\tApplyng weights: {sum(bad)} / {len(bad)} photon pixels are outside weight region')
    if sum(bad)==len(bad):
        a = np.array(healpy.pix2ang(nside_wt, wt_pix, nest=True, lonlat=True)).mean(axis=1).round(1)
        b = np.array(healpy.pix2ang(nside_wt, shifted_pix, nest=True, lonlat=True)).mean(axis=1).round(1)

        raise Exception(f'There was no overlap of the photon data at {b} and the weights at {a}')
    shifted_pix[bad] = 12*nside_wt**2 # set index to be beyond pixel indices

    # find indices with search and add a "weights" column
    # (expect that wt_pix are NEST ordering and sorted)
    weight_index = np.searchsorted(wt_pix,shifted_pix)
    band_index = np.fmin(31, photon_data.band.values) #all above 1 TeV into last bin

    # final grand lookup -- isn't numpy wonderful!
    photon_data.loc[:,'weight'] = wts[tuple([band_index, weight_index])]
    if config.verbose>0:
        print(f'\t{sum(np.isnan(photon_data.weight.values))} weights set to NaN')

# Cell
def add_weights(xconfig, xfiles, photon_data, source):
    """ add weights for the soruce to the photons data
    """
    global config, files
    config = xconfig
    files = xfiles

    weight_file =  os.path.join(files.weights, source.name+'_weights.pkl')
    assert os.path.exists(weight_file)

    wts, wt_pix, nside_wt = _load_weights(weight_file)
    _add_weights(wts, wt_pix, nside_wt, photon_data)